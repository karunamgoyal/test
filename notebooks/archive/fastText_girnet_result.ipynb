{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### include useful folders\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../vendors/mtl_girnet/data_prep/\")\n",
    "\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "\n",
    "# tokenizer\n",
    "from twokenize import tokenizeRawTweetText as tokenize\n",
    "\n",
    "# for a particular dataset\n",
    "from xml.dom import minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code-Mixed: en_es_wssa_data: 3062\n",
      "Spanish: es2_twitter_data: 3202\n",
      "Spanish: es_tass1_data: 7217\n",
      "English: en_twitter_data: 4241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### SemEval 2017 Task A\n",
    "\n",
    "df = pd.read_csv(\"../data/datastories-semeval2017-task4/dataset/Subtask_A/4A-English/SemEval2017-task4-dev.subtask-A.english.INPUT.txt\", sep=\"\\t\", header=None)\n",
    "\n",
    "decode_map = {\"negative\": -1, \"neutral\": 0, \"positive\": 1}\n",
    "\n",
    "df[1] = df[1].apply(lambda x: decode_map[x])\n",
    "df[2] = df[2].apply(lambda x: tokenize(x))\n",
    "\n",
    "data = map( lambda x :{'sentiment': x[1] , 'tokens': x[2] , 'text': ' '.join(x[2])} , df.to_numpy() )\n",
    "\n",
    "en_semeval_17 = list(data)\n",
    "\n",
    "\n",
    "### English-Spanish Code Mixed Data \n",
    "\n",
    "sents = {\"N\":-1 , \"P\" :1 , \"NONE\":0}\n",
    "\n",
    "data = open(\"../vendors/mtl_girnet/data_prep/data_cm_senti/cs-corpus-with-tweets_train.txt\", encoding='utf-8').read().split(\"\\n\") \n",
    "data = map( lambda x : x.split(\"\\t\") , data )\n",
    "data = map( lambda x :{'sentiment': sents[x[1]] , 'tokens': tokenize(x[2]) , 'text': x[2] } , data )\n",
    "en_es_wssa_data_train = list(data)\n",
    "\n",
    "data = open(\"../vendors/mtl_girnet/data_prep/data_cm_senti/cs-corpus-with-tweets_test.txt\", encoding='utf-8').read().split(\"\\n\") \n",
    "data = map( lambda x : x.split(\"\\t\") , data )\n",
    "data = map( lambda x :{'sentiment': sents[x[1]] , 'tokens': tokenize(x[2]) , 'text': x[2] } , data )\n",
    "en_es_wssa_data_test = list(data)\n",
    "\n",
    "en_es_wssa_data = list(en_es_wssa_data_train) + list(en_es_wssa_data_test)\n",
    "\n",
    "### Spanish Tweet Dataset\n",
    "\n",
    "xmldoc = minidom.parse(\"../vendors/mtl_girnet/data_prep/data_cm_senti/general-tweets-train-tagged.xml\")\n",
    "tweets = xmldoc.getElementsByTagName('tweet')\n",
    "\n",
    "sents = {\"N\":-1 , \"P\" :1 , \"NEU\":0 , 'NONE':0 , \"P+\" : 1 , \"N+\":-1 }\n",
    "\n",
    "\n",
    "es_tass1_data = []\n",
    "\n",
    "for i in range( len(tweets)-1) :\n",
    "    if i == 6055:\n",
    "        continue # bad jogar\n",
    "    textt = tweets[i].getElementsByTagName('content')[0].childNodes[0].data\n",
    "    words = tokenize( textt )\n",
    "    sentiment = tweets[i].getElementsByTagName('polarity')[0].getElementsByTagName('value')[0].childNodes[0].data\n",
    "    assert len(tweets[i].getElementsByTagName('polarity')[0].getElementsByTagName('entity'))==0\n",
    "    es_tass1_data.append({'text':textt , 'tokens':words , 'sentiment': sents[sentiment] })\n",
    "\n",
    "### Some english tweet data\n",
    "\n",
    "data = open(\"../vendors/mtl_girnet/data_prep/data_cm_senti/twitter4242.txt\", \"r\", encoding=\"utf-8\",errors='ignore').read().split(\"\\n\")[1:-1]\n",
    "data = map( lambda x : x.split(\"\\t\") , data )\n",
    "data = map( lambda x :{'sentiment': int(np.sign(int(x[0])-int(x[1]))) , 'tokens': tokenize(x[2]) , 'text': x[2] } , data )\n",
    "\n",
    "en_twitter_data = list(data)\n",
    "\n",
    "### es2_twitter_data\n",
    "\n",
    "data = open(\"../vendors/mtl_girnet/data_prep/data_cm_senti/1600_tweets_dev_complete.txt\", encoding=\"utf-8\").read().split(\"\\n\")[1:-1]\n",
    "data += open(\"../vendors/mtl_girnet/data_prep/data_cm_senti/1600_tweets_test_average_complete.tsv\", encoding=\"utf-8\").read().split(\"\\n\")[1:-2]\n",
    "\n",
    "data = map( lambda x : x.split(\"\\t\") , data )\n",
    "data = map( lambda x :{'sentiment': int(np.sign(int(x[0])-int(x[1]))) , 'tokens': tokenize(x[2]) , 'text': x[2] } , data )\n",
    "\n",
    "es2_twitter_data = list(data)\n",
    "\n",
    "def get_y(data):\n",
    "    from keras.utils import to_categorical\n",
    "    y = []\n",
    "    for row in data:\n",
    "        y.append(int(row['sentiment']))\n",
    "    y = to_categorical(y,num_classes=3)\n",
    "    return y\n",
    "\n",
    "\n",
    "print(\"Code-Mixed: en_es_wssa_data: %d\" % len(en_es_wssa_data))\n",
    "print(\"Spanish: es2_twitter_data: %d\" % len(es2_twitter_data))\n",
    "print(\"Spanish: es_tass1_data: %d\" % len(es_tass1_data))\n",
    "print(\"English: en_twitter_data: %d\" % len(en_twitter_data))\n",
    "# print(\"English: en_sentiment140: %d\" %len(en_sentiment140))\n",
    "en_es_y =  get_y(en_es_wssa_data)\n",
    "en_es_y_train =  get_y(en_es_wssa_data_train)\n",
    "en_es_y_test =  get_y(en_es_wssa_data_test)\n",
    "es_twitter_y = get_y(es2_twitter_data)\n",
    "es_tass_y = get_y(es_tass1_data)\n",
    "en_twitter_y = get_y(en_twitter_data)\n",
    "en_semeval_17_y = get_y(en_semeval_17)\n",
    "# en_sentiment140_y = get_y(en_sentiment140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(en_semeval_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_analysis = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = en_es_wssa_data_train\n",
    "# lang = \"cm\"\n",
    "# for sent in data:\n",
    "#     sentiment_analysis.append(\"\\t\".join([sent['text'], str(sent['sentiment']), lang, \"\\n\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"train.txt\", \"w\") as f:\n",
    "#     f.writelines(sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "def get_class_weight(y):\n",
    "    \"\"\"\n",
    "    Used from: https://stackoverflow.com/a/50695814\n",
    "    TODO: check validity and 'balanced' option\n",
    "    :param y: A list of one-hot-encoding labels [[0,0,1,0],[0,0,0,1],..]\n",
    "    :return: class-weights to be used by keras model.fit(.. class_weight=\"\") -> {0:0.52134, 1:1.adas..}\n",
    "    \"\"\"\n",
    "    y_integers = np.argmax(y, axis=1)\n",
    "    class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "    return d_class_weights\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import losses\n",
    "\n",
    "def loss_ordinal(y_true, y_pred):\n",
    "    weights = K.cast(K.abs(K.argmax(y_true, axis=1) - K.argmax(y_pred, axis=1))/(K.int_shape(y_pred)[1] - 1), dtype='float32')\n",
    "    return (1.0 + weights) * losses.categorical_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install bpemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting dim=300 for multilingual BPEmb\n",
      "BPEmb fallback: multi from vocab size 1000 to 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "from bpemb import BPEmb\n",
    "multibpemb = BPEmb(lang=\"multi\", vs=1000, dim=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = multibpemb.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPEmb(lang=multi, vs=100000, dim=300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multibpemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32\n",
    "zero_vector = [0 for _ in range(300)]\n",
    "def get_x(data_):\n",
    "    x_  = []\n",
    "    for sent in data_:\n",
    "        pred = list(multibpemb.embed(sent['text']))\n",
    "        if len(pred) >= 32:\n",
    "            pred = pred[:32]\n",
    "        else:\n",
    "            counter = len(pred)\n",
    "            while counter < max_len:\n",
    "                pred.append(zero_vector)\n",
    "                counter = counter + 1\n",
    "        x_.append(pred)\n",
    "    return np.array(x_)\n",
    "en_es_x =  get_x(en_es_wssa_data)\n",
    "es_twitter_x = get_x(es2_twitter_data)\n",
    "es_tass_x = get_x(es_tass1_data)\n",
    "en_twitter_x = get_x(en_twitter_data)\n",
    "en_semeval_17_x = get_x(en_semeval_17)\n",
    "en_es_x_train =  get_x(en_es_wssa_data_train)\n",
    "en_es_x_test =  get_x(en_es_wssa_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GET Y PADDED TOKENS NUMBER\n",
    "max_len = 32\n",
    "def get_x(data_):\n",
    "    x_  = []\n",
    "    for sent in data_:\n",
    "        pred = list(multibpemb.encode_ids(sent['text']))\n",
    "        if len(pred) >= 32:\n",
    "            pred = pred[:32]\n",
    "        else:\n",
    "            counter = len(pred)\n",
    "            while counter < max_len:\n",
    "                pred.append(0)\n",
    "                counter = counter + 1\n",
    "        x_.append(pred)\n",
    "    return np.array(x_)\n",
    "en_es_x =  get_x(en_es_wssa_data)\n",
    "es_twitter_x = get_x(es2_twitter_data)\n",
    "es_tass_x = get_x(es_tass1_data)\n",
    "en_twitter_x = get_x(en_twitter_data)\n",
    "en_semeval_17_x = get_x(en_semeval_17)\n",
    "en_es_x_train =  get_x(en_es_wssa_data_train)\n",
    "en_es_x_test =  get_x(en_es_wssa_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embed = fasttext.load_model('../vendors/language-models/all_p_fasttext.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32\n",
    "zero_vector = [0 for _ in range(100)]\n",
    "def get_x(data_):\n",
    "#     x_  = []\n",
    "#     for sent in data_:\n",
    "#         x_.append(embed.get_sentence_vector(sent['text'].replace(\"\\n\",\" \")))\n",
    "#     return np.array(x_)\n",
    "    x_  = []\n",
    "    for sent in data_:\n",
    "        tokenised = fasttext.tokenize(sent['text'])\n",
    "        sent_vector = []\n",
    "        counter = 0\n",
    "        for token in tokenised:\n",
    "            if counter >= max_len:\n",
    "                break\n",
    "            else:\n",
    "                sent_vector.append(embed[token])\n",
    "                counter = counter + 1\n",
    "        \n",
    "        if counter < max_len:\n",
    "            sent_vector.append(embed['</s>'])\n",
    "            counter = counter + 1\n",
    "                               \n",
    "        while counter < max_len:\n",
    "            sent_vector.append(zero_vector)\n",
    "            counter = counter + 1\n",
    "            \n",
    "        x_.append(sent_vector)\n",
    "        \n",
    "    return np.array(x_)\n",
    "\n",
    "en_es_x =  get_x(en_es_wssa_data)\n",
    "es_twitter_x = get_x(es2_twitter_data)\n",
    "es_tass_x = get_x(es_tass1_data)\n",
    "en_twitter_x = get_x(en_twitter_data)\n",
    "en_semeval_17_x = get_x(en_semeval_17)\n",
    "en_es_x_train =  get_x(en_es_wssa_data_train)\n",
    "en_es_x_test =  get_x(en_es_wssa_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from attention_lstm import AttentionWithContext\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(100,)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, dropout=0.3, input_shape=(32, 100), recurrent_dropout=0.3, return_sequences=True)))\n",
    "model.add(AttentionWithContext())\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-self-attention\n",
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, input_shape=(None, 32, 100))))\n",
    "# model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=loss_ordinal,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(3,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1, input_shape=(32, 300)))\n",
    "# model.add(MaxPooling1D(pool_size=pool_size))\n",
    "# model.add(Conv1D(5,\n",
    "#                  64,\n",
    "#                  padding='valid',\n",
    "#                  activation='relu',\n",
    "#                  strides=1))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(LSTM(50, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_f1', mode='max', verbose=1, patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit(en_es_x_train, en_es_y_train, epochs=10, shuffle=True, validation_data=(en_es_x_test\n",
    "#                                                                                             ,en_es_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 16505 samples, validate on 4127 samples\n",
      "Epoch 1/20\n",
      "16505/16505 [==============================] - 51s 3ms/step - loss: 0.8663 - acc: 0.5896 - f1: 0.5304 - val_loss: 0.8403 - val_acc: 0.5939 - val_f1: 0.5762\n",
      "Epoch 2/20\n",
      "16505/16505 [==============================] - 49s 3ms/step - loss: 0.7743 - acc: 0.6503 - f1: 0.6303 - val_loss: 0.7985 - val_acc: 0.6208 - val_f1: 0.6046\n",
      "Epoch 3/20\n",
      "16505/16505 [==============================] - 50s 3ms/step - loss: 0.7523 - acc: 0.6596 - f1: 0.6443 - val_loss: 0.7942 - val_acc: 0.6283 - val_f1: 0.6130\n",
      "Epoch 4/20\n",
      "16505/16505 [==============================] - 48s 3ms/step - loss: 0.7356 - acc: 0.6698 - f1: 0.6560 - val_loss: 0.7797 - val_acc: 0.6365 - val_f1: 0.6227\n",
      "Epoch 5/20\n",
      "16505/16505 [==============================] - 48s 3ms/step - loss: 0.7250 - acc: 0.6774 - f1: 0.6645 - val_loss: 0.7943 - val_acc: 0.6208 - val_f1: 0.6123\n",
      "Epoch 6/20\n",
      "16505/16505 [==============================] - 48s 3ms/step - loss: 0.7144 - acc: 0.6839 - f1: 0.6696 - val_loss: 0.7648 - val_acc: 0.6455 - val_f1: 0.6306\n",
      "Epoch 7/20\n",
      "16505/16505 [==============================] - 48s 3ms/step - loss: 0.7055 - acc: 0.6871 - f1: 0.6759 - val_loss: 0.7711 - val_acc: 0.6443 - val_f1: 0.6308\n",
      "Epoch 8/20\n",
      "16505/16505 [==============================] - 48s 3ms/step - loss: 0.6933 - acc: 0.6929 - f1: 0.6804 - val_loss: 0.7835 - val_acc: 0.6365 - val_f1: 0.6287\n",
      "Epoch 9/20\n",
      "16505/16505 [==============================] - 48s 3ms/step - loss: 0.6865 - acc: 0.6935 - f1: 0.6833 - val_loss: 0.7602 - val_acc: 0.6513 - val_f1: 0.6351\n",
      "Epoch 10/20\n",
      "16505/16505 [==============================] - 48s 3ms/step - loss: 0.6817 - acc: 0.6967 - f1: 0.6867 - val_loss: 0.7828 - val_acc: 0.6460 - val_f1: 0.6343\n",
      "Epoch 11/20\n",
      "16505/16505 [==============================] - 51s 3ms/step - loss: 0.6703 - acc: 0.7052 - f1: 0.6967 - val_loss: 0.7613 - val_acc: 0.6545 - val_f1: 0.6459\n",
      "Epoch 12/20\n",
      "16505/16505 [==============================] - 55s 3ms/step - loss: 0.6686 - acc: 0.7045 - f1: 0.6943 - val_loss: 0.7517 - val_acc: 0.6564 - val_f1: 0.6454\n",
      "Epoch 13/20\n",
      "16505/16505 [==============================] - 55s 3ms/step - loss: 0.6650 - acc: 0.7035 - f1: 0.6953 - val_loss: 0.7619 - val_acc: 0.6501 - val_f1: 0.6426\n",
      "Epoch 14/20\n",
      "16505/16505 [==============================] - 55s 3ms/step - loss: 0.6552 - acc: 0.7105 - f1: 0.7019 - val_loss: 0.7677 - val_acc: 0.6552 - val_f1: 0.6415\n",
      "Epoch 15/20\n",
      "16505/16505 [==============================] - 55s 3ms/step - loss: 0.6481 - acc: 0.7123 - f1: 0.7034 - val_loss: 0.7525 - val_acc: 0.6600 - val_f1: 0.6492\n",
      "Epoch 16/20\n",
      "16505/16505 [==============================] - 55s 3ms/step - loss: 0.6422 - acc: 0.7149 - f1: 0.7077 - val_loss: 0.7570 - val_acc: 0.6535 - val_f1: 0.6478\n",
      "Epoch 17/20\n",
      "16505/16505 [==============================] - 50s 3ms/step - loss: 0.6361 - acc: 0.7172 - f1: 0.7093 - val_loss: 0.7723 - val_acc: 0.6571 - val_f1: 0.6475\n",
      "Epoch 18/20\n",
      "16505/16505 [==============================] - 48s 3ms/step - loss: 0.6299 - acc: 0.7209 - f1: 0.7125 - val_loss: 0.7728 - val_acc: 0.6530 - val_f1: 0.6428\n",
      "Epoch 19/20\n",
      "16505/16505 [==============================] - 48s 3ms/step - loss: 0.6252 - acc: 0.7243 - f1: 0.7166 - val_loss: 0.7549 - val_acc: 0.6632 - val_f1: 0.6532\n",
      "Epoch 20/20\n",
      "16505/16505 [==============================] - 47s 3ms/step - loss: 0.6205 - acc: 0.7275 - f1: 0.7201 - val_loss: 0.7629 - val_acc: 0.6576 - val_f1: 0.6484\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(en_semeval_17_x, en_semeval_17_y, epochs=20, initial_epoch=0, validation_split=0.2, shuffle=True, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8596599811344707, 0.6084828711256117, 0.5769225707061917]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(en_es_x_test, en_es_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5773 samples, validate on 1444 samples\n",
      "Epoch 21/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.9434 - acc: 0.5486 - f1: 0.4771 - val_loss: 0.8299 - val_acc: 0.6191 - val_f1: 0.5794\n",
      "Epoch 22/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.8495 - acc: 0.6099 - f1: 0.5604 - val_loss: 0.8071 - val_acc: 0.6343 - val_f1: 0.6043\n",
      "Epoch 23/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.8191 - acc: 0.6300 - f1: 0.5851 - val_loss: 0.7876 - val_acc: 0.6447 - val_f1: 0.6063\n",
      "Epoch 24/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.8024 - acc: 0.6392 - f1: 0.5900 - val_loss: 0.7725 - val_acc: 0.6503 - val_f1: 0.6140\n",
      "Epoch 25/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.7906 - acc: 0.6451 - f1: 0.6024 - val_loss: 0.7719 - val_acc: 0.6503 - val_f1: 0.6174\n",
      "Epoch 26/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.7839 - acc: 0.6461 - f1: 0.6083 - val_loss: 0.7761 - val_acc: 0.6461 - val_f1: 0.6184\n",
      "Epoch 27/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.7650 - acc: 0.6570 - f1: 0.6191 - val_loss: 0.7720 - val_acc: 0.6551 - val_f1: 0.6257\n",
      "Epoch 28/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.7622 - acc: 0.6553 - f1: 0.6241 - val_loss: 0.7678 - val_acc: 0.6524 - val_f1: 0.6296\n",
      "Epoch 29/35\n",
      "5773/5773 [==============================] - 16s 3ms/step - loss: 0.7519 - acc: 0.6603 - f1: 0.6364 - val_loss: 0.7851 - val_acc: 0.6378 - val_f1: 0.6143\n",
      "Epoch 30/35\n",
      "5773/5773 [==============================] - 16s 3ms/step - loss: 0.7404 - acc: 0.6723 - f1: 0.6401 - val_loss: 0.7704 - val_acc: 0.6524 - val_f1: 0.6339\n",
      "Epoch 31/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.7250 - acc: 0.6782 - f1: 0.6555 - val_loss: 0.7736 - val_acc: 0.6406 - val_f1: 0.6209\n",
      "Epoch 32/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.7213 - acc: 0.6820 - f1: 0.6508 - val_loss: 0.7581 - val_acc: 0.6669 - val_f1: 0.6489\n",
      "Epoch 33/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.7138 - acc: 0.6821 - f1: 0.6541 - val_loss: 0.7800 - val_acc: 0.6517 - val_f1: 0.6390\n",
      "Epoch 34/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.7049 - acc: 0.6915 - f1: 0.6672 - val_loss: 0.7758 - val_acc: 0.6454 - val_f1: 0.6297\n",
      "Epoch 35/35\n",
      "5773/5773 [==============================] - 17s 3ms/step - loss: 0.6958 - acc: 0.6899 - f1: 0.6754 - val_loss: 0.7739 - val_acc: 0.6600 - val_f1: 0.6374\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(es_tass_x, es_tass_y, epochs=35, initial_epoch=20, validation_split=0.2, shuffle=True, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0563770489824926, 0.5138662318421032, 0.4927767060125827]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(en_es_x_test, en_es_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2561 samples, validate on 641 samples\n",
      "Epoch 36/40\n",
      "2561/2561 [==============================] - 8s 3ms/step - loss: 0.9673 - acc: 0.5517 - f1: 0.4960 - val_loss: 0.9054 - val_acc: 0.5788 - val_f1: 0.4871\n",
      "Epoch 37/40\n",
      "2561/2561 [==============================] - 8s 3ms/step - loss: 0.9028 - acc: 0.5814 - f1: 0.5019 - val_loss: 0.9065 - val_acc: 0.5913 - val_f1: 0.5097\n",
      "Epoch 38/40\n",
      "2561/2561 [==============================] - 8s 3ms/step - loss: 0.8752 - acc: 0.5955 - f1: 0.5485 - val_loss: 0.9091 - val_acc: 0.5835 - val_f1: 0.5320\n",
      "Epoch 39/40\n",
      "2561/2561 [==============================] - 8s 3ms/step - loss: 0.8612 - acc: 0.6076 - f1: 0.5536 - val_loss: 0.8794 - val_acc: 0.6147 - val_f1: 0.5320\n",
      "Epoch 40/40\n",
      "2561/2561 [==============================] - 7s 3ms/step - loss: 0.8454 - acc: 0.6107 - f1: 0.5671 - val_loss: 0.9165 - val_acc: 0.5803 - val_f1: 0.5443\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(es_twitter_x, es_twitter_y, epochs=40, initial_epoch=35, validation_split=0.2, shuffle=True,  callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 1s 998us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8807512282547321, 0.579119086557267, 0.5189811075881099]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(en_es_x_test, en_es_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate([en_semeval_17_x, en_twitter_x, es_tass_x, es_twitter_x])\n",
    "y = np.concatenate([en_semeval_17_y, en_twitter_y, es_tass_y, es_twitter_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35292 samples, validate on 2449 samples\n",
      "Epoch 41/60\n",
      "35292/35292 [==============================] - 96s 3ms/step - loss: 0.7452 - acc: 0.6644 - f1: 0.6416 - val_loss: 0.8750 - val_acc: 0.5900 - val_f1: 0.5296\n",
      "Epoch 42/60\n",
      "35292/35292 [==============================] - 95s 3ms/step - loss: 0.7247 - acc: 0.6756 - f1: 0.6572 - val_loss: 0.8606 - val_acc: 0.5970 - val_f1: 0.5448\n",
      "Epoch 43/60\n",
      "35292/35292 [==============================] - 94s 3ms/step - loss: 0.7169 - acc: 0.6766 - f1: 0.6590 - val_loss: 0.8646 - val_acc: 0.5986 - val_f1: 0.5426\n",
      "Epoch 44/60\n",
      "35292/35292 [==============================] - 94s 3ms/step - loss: 0.7092 - acc: 0.6832 - f1: 0.6654 - val_loss: 0.8539 - val_acc: 0.6015 - val_f1: 0.5482\n",
      "Epoch 45/60\n",
      "35292/35292 [==============================] - 96s 3ms/step - loss: 0.7031 - acc: 0.6874 - f1: 0.6712 - val_loss: 0.8573 - val_acc: 0.6002 - val_f1: 0.5556\n",
      "Epoch 46/60\n",
      "35292/35292 [==============================] - 104s 3ms/step - loss: 0.7001 - acc: 0.6894 - f1: 0.6728 - val_loss: 0.8531 - val_acc: 0.5998 - val_f1: 0.5501\n",
      "Epoch 47/60\n",
      "35292/35292 [==============================] - 110s 3ms/step - loss: 0.6939 - acc: 0.6885 - f1: 0.6737 - val_loss: 0.8778 - val_acc: 0.5855 - val_f1: 0.5321\n",
      "Epoch 48/60\n",
      "35292/35292 [==============================] - 110s 3ms/step - loss: 0.6881 - acc: 0.6924 - f1: 0.6778 - val_loss: 0.8517 - val_acc: 0.6047 - val_f1: 0.5538\n",
      "Epoch 49/60\n",
      "35292/35292 [==============================] - 111s 3ms/step - loss: 0.6842 - acc: 0.6942 - f1: 0.6787 - val_loss: 0.8504 - val_acc: 0.6088 - val_f1: 0.5576\n",
      "Epoch 50/60\n",
      "35292/35292 [==============================] - 109s 3ms/step - loss: 0.6818 - acc: 0.6949 - f1: 0.6799 - val_loss: 0.8622 - val_acc: 0.5888 - val_f1: 0.5379\n",
      "Epoch 51/60\n",
      "35292/35292 [==============================] - 111s 3ms/step - loss: 0.6761 - acc: 0.7000 - f1: 0.6855 - val_loss: 0.8534 - val_acc: 0.5990 - val_f1: 0.5538\n",
      "Epoch 52/60\n",
      "35292/35292 [==============================] - 110s 3ms/step - loss: 0.6738 - acc: 0.7013 - f1: 0.6884 - val_loss: 0.8375 - val_acc: 0.6203 - val_f1: 0.5774\n",
      "Epoch 53/60\n",
      "35292/35292 [==============================] - 110s 3ms/step - loss: 0.6707 - acc: 0.7020 - f1: 0.6883 - val_loss: 0.8788 - val_acc: 0.5794 - val_f1: 0.5404\n",
      "Epoch 54/60\n",
      "35292/35292 [==============================] - 110s 3ms/step - loss: 0.6661 - acc: 0.7051 - f1: 0.6906 - val_loss: 0.8466 - val_acc: 0.6141 - val_f1: 0.5646\n",
      "Epoch 55/60\n",
      "35292/35292 [==============================] - 110s 3ms/step - loss: 0.6636 - acc: 0.7072 - f1: 0.6957 - val_loss: 0.8642 - val_acc: 0.5953 - val_f1: 0.5522\n",
      "Epoch 56/60\n",
      "35292/35292 [==============================] - 98s 3ms/step - loss: 0.6583 - acc: 0.7086 - f1: 0.6958 - val_loss: 0.8534 - val_acc: 0.6068 - val_f1: 0.5632\n",
      "Epoch 57/60\n",
      "35292/35292 [==============================] - 218s 6ms/step - loss: 0.6580 - acc: 0.7089 - f1: 0.6962 - val_loss: 0.8760 - val_acc: 0.5904 - val_f1: 0.5445\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00057: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=60, initial_epoch=40,validation_data=(en_es_x_train,en_es_y_train), shuffle=True, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7836689443417124, 0.6574225123321447, 0.60803509546143]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(en_es_x_test, en_es_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2449 samples, validate on 613 samples\n",
      "Epoch 61/80\n",
      "2449/2449 [==============================] - 8s 3ms/step - loss: 0.8355 - acc: 0.6174 - f1: 0.5727 - val_loss: 0.7602 - val_acc: 0.6639 - val_f1: 0.6314\n",
      "Epoch 62/80\n",
      "2449/2449 [==============================] - 8s 3ms/step - loss: 0.7964 - acc: 0.6497 - f1: 0.6239 - val_loss: 0.7387 - val_acc: 0.6591 - val_f1: 0.6467\n",
      "Epoch 63/80\n",
      "2449/2449 [==============================] - 8s 3ms/step - loss: 0.7695 - acc: 0.6697 - f1: 0.6378 - val_loss: 0.7397 - val_acc: 0.6639 - val_f1: 0.6494\n",
      "Epoch 64/80\n",
      "2449/2449 [==============================] - 8s 3ms/step - loss: 0.7449 - acc: 0.6823 - f1: 0.6531 - val_loss: 0.7454 - val_acc: 0.6672 - val_f1: 0.6457\n",
      "Epoch 65/80\n",
      "2449/2449 [==============================] - 8s 3ms/step - loss: 0.7258 - acc: 0.6750 - f1: 0.6584 - val_loss: 0.7283 - val_acc: 0.6786 - val_f1: 0.6673\n",
      "Epoch 66/80\n",
      "2449/2449 [==============================] - 8s 3ms/step - loss: 0.7268 - acc: 0.6880 - f1: 0.6710 - val_loss: 0.7242 - val_acc: 0.6786 - val_f1: 0.6622\n",
      "Epoch 67/80\n",
      "2449/2449 [==============================] - 7s 3ms/step - loss: 0.7038 - acc: 0.6958 - f1: 0.6811 - val_loss: 0.7289 - val_acc: 0.6721 - val_f1: 0.6521\n",
      "Epoch 68/80\n",
      "2449/2449 [==============================] - 7s 3ms/step - loss: 0.6848 - acc: 0.7056 - f1: 0.6872 - val_loss: 0.7287 - val_acc: 0.6721 - val_f1: 0.6657\n",
      "Epoch 69/80\n",
      "2449/2449 [==============================] - 7s 3ms/step - loss: 0.6608 - acc: 0.7109 - f1: 0.7044 - val_loss: 0.7296 - val_acc: 0.6721 - val_f1: 0.6629\n",
      "Epoch 70/80\n",
      "2449/2449 [==============================] - 7s 3ms/step - loss: 0.6567 - acc: 0.7166 - f1: 0.7029 - val_loss: 0.7348 - val_acc: 0.6737 - val_f1: 0.6703\n",
      "Epoch 71/80\n",
      "2449/2449 [==============================] - 7s 3ms/step - loss: 0.6598 - acc: 0.7207 - f1: 0.7031 - val_loss: 0.7238 - val_acc: 0.6688 - val_f1: 0.6656\n",
      "Epoch 72/80\n",
      "2449/2449 [==============================] - 7s 3ms/step - loss: 0.6461 - acc: 0.7252 - f1: 0.7069 - val_loss: 0.7362 - val_acc: 0.6770 - val_f1: 0.6670\n",
      "Epoch 73/80\n",
      "2449/2449 [==============================] - 7s 3ms/step - loss: 0.6219 - acc: 0.7330 - f1: 0.7233 - val_loss: 0.7466 - val_acc: 0.6672 - val_f1: 0.6556\n",
      "Epoch 74/80\n",
      "2449/2449 [==============================] - 7s 3ms/step - loss: 0.6040 - acc: 0.7448 - f1: 0.7334 - val_loss: 0.7487 - val_acc: 0.6639 - val_f1: 0.6560\n",
      "Epoch 75/80\n",
      "2449/2449 [==============================] - 6s 3ms/step - loss: 0.5888 - acc: 0.7562 - f1: 0.7441 - val_loss: 0.7665 - val_acc: 0.6493 - val_f1: 0.6440\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00075: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(en_es_x_train, en_es_y_train, epochs=80, initial_epoch=60, validation_data=(en_es_x_test, en_es_y_test), shuffle=True,  callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 1s 972us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7347888143377631, 0.6737357259380098, 0.6703014879397817]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(en_es_x_test, en_es_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from attention_lstm import AttentionWithContext\n",
    "from keras.callbacks import *\n",
    "# from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GiretTwoCell(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, cell_1 , cell_2 , nHidden , **kwargs):\n",
    "        self.cell_1 = cell_1\n",
    "        self.cell_2 = cell_2\n",
    "        self.nHidden = nHidden\n",
    "        self.state_size = [nHidden,nHidden]\n",
    "        super(GiretTwoCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        nHidden = self.nHidden\n",
    "        \n",
    "        input_shape_n = ( input_shape[0] , input_shape[1]- 2 )\n",
    "#         print \"pp\", input_shape_n\n",
    "        \n",
    "#         self.cell_1.build(input_shape_n)\n",
    "#         self.cell_2.build(input_shape_n)\n",
    "        \n",
    "        self._trainable_weights += ( self.cell_1.trainable_weights )\n",
    "        self._trainable_weights += ( self.cell_2.trainable_weights )\n",
    "        \n",
    "        self._non_trainable_weights += (  self.cell_1.non_trainable_weights )\n",
    "        self._non_trainable_weights += (  self.cell_2.non_trainable_weights )\n",
    "        \n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        \n",
    "        nHidden = self.nHidden\n",
    "        \n",
    "        gate_val_1 = inputs[ : , 0:1]\n",
    "        gate_val_2 = inputs[ : , 1:2]\n",
    "        \n",
    "        inputs  = inputs[ : , 2: ]\n",
    "                \n",
    "        gate_val_1 = K.repeat_elements(gate_val_1 , nHidden , -1 ) # shape # bs , hidden\n",
    "        gate_val_2 = K.repeat_elements(gate_val_2 , nHidden , -1 ) # shape # bs , hidden\n",
    "        \n",
    "        _ , [h1 , c1 ]  = self.cell_1.call( inputs , states )\n",
    "        _ , [h2 , c2 ]  = self.cell_2.call( inputs , states )\n",
    "        \n",
    "        h = gate_val_1*h1 + gate_val_2*h2  + (1 - gate_val_1 -  gate_val_2 )*states[0]\n",
    "        c = gate_val_1*c1 + gate_val_2*c2  + (1 - gate_val_1 -  gate_val_2 )*states[1]\n",
    "        \n",
    "        return h, [h , c ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 100\n",
    "dims = 100\n",
    "\n",
    "rnn_en = LSTM(hidden, name='en_lstm', recurrent_dropout=0.3, dropout=0.3)\n",
    "rnn_hi = LSTM(hidden, name='es_lstm', recurrent_dropout=0.3, dropout=0.3)\n",
    "\n",
    "       \n",
    "# en\n",
    "inp_en = Input(shape=(32, dims))\n",
    "rnn_en_ = rnn_en(inp_en)\n",
    "x = Dropout(0.3)(rnn_en_)\n",
    "out_en = Dense(3, activation='softmax', name='en')(x)\n",
    "\n",
    "\n",
    "# es\n",
    "inp_hi = Input(shape=(32, dims))\n",
    "rnn_hi_ = rnn_hi(inp_hi)\n",
    "x = Dropout(0.3)(rnn_hi_)\n",
    "out_hi = Dense(3, activation='softmax', name='es')(x)\n",
    "\n",
    "\n",
    "cell_combined = GiretTwoCell(rnn_en.cell , rnn_hi.cell , hidden)\n",
    "\n",
    "        \n",
    "inp_enhi = Input(shape=(32, dims))\n",
    "x = inp_enhi\n",
    "x_att = x\n",
    "x_att = Bidirectional(LSTM(32 , return_sequences=True, recurrent_dropout=0.3, dropout=0.3))( x )\n",
    "bider_h = x_att \n",
    "x_att = Dropout(0.3)(x_att)\n",
    "x_att = TimeDistributed(Dense(3, activation='softmax') )(x_att)\n",
    "x_att = Lambda(lambda x : x[... , 1: ])(x_att)\n",
    "\n",
    "x = Concatenate(-1)([x_att , x ])\n",
    "\n",
    "x =  RNN(cell_combined, name='damn')(x)\n",
    "# x = AttentionWithContext()(x)\n",
    "out_enhi = Dense(3, activation='softmax', name='cm')(x)\n",
    "        \n",
    "model = Model( [inp_en , inp_hi , inp_enhi  ] , [ out_en , out_hi , out_enhi ] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 64\n",
    "numwords = weight_matrix.shape[0]\n",
    "hidden_emd_dim = 300\n",
    "\n",
    "\n",
    "embed = Embedding(numwords, hidden_emd_dim, weights=[weight_matrix])\n",
    "conv1 = Conv1D(128, 3, activation='relu', padding='valid',strides=1)\n",
    "pool1 = MaxPooling1D(2)\n",
    "conv2 = Conv1D(128, 5, activation='relu', padding='valid', strides=1)\n",
    "pool2 = MaxPooling1D(2)\n",
    "# conv3 = Conv1D(128, 5, activation='relu', padding='valid', strides=1)\n",
    "# pool3 = MaxPooling1D(2)\n",
    "# conv3 = Conv1D(128, 5, activation='relu', padding='valid',strides=1)\n",
    "# pool3 = MaxPooling1D(35)  # global max pooling\n",
    "\n",
    "\n",
    "rnn_en = LSTM(hidden, name='en_lstm', recurrent_dropout=0.3, dropout=0.3)\n",
    "rnn_hi = LSTM(hidden, name=\"hi_lstm\", recurrent_dropout=0.3, dropout=0.3)\n",
    "       \n",
    "# en\n",
    "inp_en = Input((None, ))\n",
    "x = embed(inp_en)\n",
    "x = conv1(x)\n",
    "x = pool1(x)\n",
    "x = conv2(x)\n",
    "x = pool2(x)\n",
    "# x = conv3(x)\n",
    "# x = pool3(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = rnn_en(x)\n",
    "out_en = Dense(3, activation='softmax')(x)\n",
    "\n",
    "\n",
    "# es\n",
    "inp_hi = Input((None, ))\n",
    "x = embed(inp_hi)\n",
    "x = conv1(x)\n",
    "x = pool1(x)\n",
    "x = conv2(x)\n",
    "x = pool2(x)\n",
    "# x = conv3(x)\n",
    "# x = pool3(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = rnn_hi( x )\n",
    "out_hi = Dense(3, activation='softmax')(x)\n",
    "\n",
    "\n",
    "cell_combined = GiretTwoCell(rnn_hi.cell , rnn_en.cell , hidden)\n",
    "\n",
    "inp_enhi = Input((None, ))\n",
    "x = embed(inp_enhi)\n",
    "x = conv1(x)\n",
    "x = pool1(x)\n",
    "x = conv2(x)\n",
    "x = pool2(x)\n",
    "# x = conv3(x)\n",
    "# x = pool3(x)\n",
    "x_att = x\n",
    "x_att = Bidirectional(LSTM(32 , return_sequences=True, recurrent_dropout=0.3, dropout=0.3))( x )\n",
    "bider_h = x_att \n",
    "x_att = Dropout(0.3)(x_att)\n",
    "x_att = TimeDistributed(Dense(3, activation='softmax') )(x_att)\n",
    "x_att = Lambda(lambda x : x[... , 1: ])(x_att)\n",
    "\n",
    "x = Concatenate(-1)([x_att , x ])\n",
    "\n",
    "x =  RNN(cell_combined, name='damn')(x)\n",
    "# x = AttentionWithContext()(x)\n",
    "out_enhi = Dense(3, activation='softmax', name='cm')(x)\n",
    "        \n",
    "model = Model( [inp_hi , inp_en , inp_enhi  ] , [ out_hi , out_en , out_enhi ] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_cm_f1', mode='max', verbose=1, patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_48 (InputLayer)           (None, 32, 100)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 32, 64)       34048       input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 32, 64)       0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 32, 3)        195         dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_46 (InputLayer)           (None, 32, 100)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_47 (InputLayer)           (None, 32, 100)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 32, 2)        0           time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "en_lstm (LSTM)                  (None, 100)          80400       input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "es_lstm (LSTM)                  (None, 100)          80400       input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 32, 102)      0           lambda_16[0][0]                  \n",
      "                                                                 input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 100)          0           en_lstm[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 100)          0           es_lstm[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "damn (RNN)                      (None, 100)          0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "en (Dense)                      (None, 3)            303         dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "es (Dense)                      (None, 3)            303         dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "cm (Dense)                      (None, 3)            303         damn[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 195,952\n",
      "Trainable params: 195,952\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_x = np.concatenate([en_twitter_x, en_semeval_17_x])\n",
    "en_y = np.concatenate([en_twitter_y, en_semeval_17_y])\n",
    "es_x = np.concatenate([es_twitter_x, es_tass_x])\n",
    "es_y = np.concatenate([es_twitter_y, es_tass_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_x = np.concatenate([en_semeval_17_x, en_twitter_x, es_tass_x, es_twitter_x, en_es_x_train])\n",
    "# all_y = np.concatenate([en_semeval_17_y, en_twitter_y, es_tass_y, es_twitter_y, en_es_y_train])\n",
    "all_x = np.concatenate([en_semeval_17_x, es_tass_x, es_twitter_x])\n",
    "all_y = np.concatenate([en_semeval_17_y, es_tass_y, es_twitter_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train_generator(batch_size=4, lang=\"cm\"):\n",
    "    b = batch_size\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "#         n3 = np.random.randint(0, en_es_x_train.shape[0] - batch_size, batch_size)\n",
    "\n",
    "\n",
    "        if lang is \"cm\": \n",
    "            n1 = np.random.randint(0, en_x.shape[0] - batch_size, batch_size)\n",
    "            n2 = np.random.randint(0, es_x.shape[0] - batch_size, batch_size)\n",
    "            p = random.random()\n",
    "            if p < 0.3:\n",
    "                p = random.random()\n",
    "                if p < 0.5:\n",
    "                    n3 = np.random.randint(0, en_x.shape[0] - batch_size, batch_size)\n",
    "                    x = [en_x[n1,:], es_x[n2,:], en_x[n3,:]]\n",
    "                    y = [en_y[n1,:], es_y[n2,:], en_y[n3,:]]\n",
    "                else:\n",
    "                    n3 = np.random.randint(0, es_x.shape[0] - batch_size, batch_size)\n",
    "                    x = [en_x[n1,:], es_x[n2,:], es_x[n3,:]]\n",
    "                    y = [en_y[n1,:], es_y[n2,:], es_y[n3,:]]\n",
    "            else:\n",
    "                n3 = np.random.randint(0, en_es_x_train.shape[0] - batch_size, batch_size)\n",
    "                x = [en_x[n1,:], es_x[n2,:], en_es_x_train[n3,:]]\n",
    "                y = [en_y[n1,:], es_y[n2,:], en_es_y_train[n3,:]]\n",
    "        elif lang is \"en\":\n",
    "            n3 = np.random.randint(0, en_x.shape[0] - batch_size, batch_size)\n",
    "            x = [en_x[n3,:], en_x[n3,:], en_x[n3,:]]\n",
    "            y = [en_y[n3,:], en_y[n3,:], en_y[n3,:]]\n",
    "        elif lang is \"es\":\n",
    "            n3 = np.random.randint(0, es_x.shape[0] - batch_size, batch_size)\n",
    "            x = [es_x[n3,:], es_x[n3,:], es_x[n3,:]]\n",
    "            y = [es_y[n3,:], es_y[n3,:], es_y[n3,:]]\n",
    "        elif lang is \"unsup\":\n",
    "            n1 = np.random.randint(0, en_x.shape[0] - batch_size, batch_size)\n",
    "            n2 = np.random.randint(0, es_x.shape[0] - batch_size, batch_size)\n",
    "            n3 = np.random.randint(0, all_x.shape[0] - batch_size, batch_size)\n",
    "            x = [en_x[n1,:], es_x[n2,:], all_x[n3,:]]\n",
    "            y = [en_y[n1,:], es_y[n2,:], all_y[n3,:]]\n",
    "            \n",
    "                 \n",
    "        \n",
    "#         x = [en_x[n1,:], es_x[n2,:], all_x[n3,:]]\n",
    "#         y = [en_y[n1,:], es_y[n2,:], all_y[n3,:]]\n",
    "#         x = [ en_es_x_train[n3,:],  en_es_x_train[n3,:], en_es_x_train[n3,:]]\n",
    "#         y = [en_es_y_train[n3,:], en_es_y_train[n3,:], en_es_y_train[n3,:]]\n",
    "        \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "200/200 [==============================] - 92s 462ms/step - loss: 3.0285 - en_loss: 1.0161 - es_loss: 1.0112 - cm_loss: 1.0013 - en_f1: 0.2601 - es_f1: 0.2465 - cm_f1: 0.2419 - val_loss: 3.1544 - val_en_loss: 1.0589 - val_es_loss: 1.0706 - val_cm_loss: 1.0249 - val_en_f1: 0.2816 - val_es_f1: 0.3490 - val_cm_f1: 0.3096\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 66s 328ms/step - loss: 2.8154 - en_loss: 0.9592 - es_loss: 0.9626 - cm_loss: 0.8935 - en_f1: 0.4297 - es_f1: 0.4113 - cm_f1: 0.4940 - val_loss: 3.1506 - val_en_loss: 1.0754 - val_es_loss: 1.0658 - val_cm_loss: 1.0093 - val_en_f1: 0.3897 - val_es_f1: 0.3993 - val_cm_f1: 0.3921\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 67s 333ms/step - loss: 2.7342 - en_loss: 0.9403 - es_loss: 0.9365 - cm_loss: 0.8573 - en_f1: 0.4447 - es_f1: 0.4499 - cm_f1: 0.5355 - val_loss: 3.0093 - val_en_loss: 1.0412 - val_es_loss: 1.0173 - val_cm_loss: 0.9507 - val_en_f1: 0.3723 - val_es_f1: 0.4291 - val_cm_f1: 0.4606\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 2.6914 - en_loss: 0.9307 - es_loss: 0.9338 - cm_loss: 0.8269 - en_f1: 0.4632 - es_f1: 0.4643 - cm_f1: 0.5665 - val_loss: 2.9887 - val_en_loss: 1.0181 - val_es_loss: 1.0354 - val_cm_loss: 0.9352 - val_en_f1: 0.4000 - val_es_f1: 0.3928 - val_cm_f1: 0.4811\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 68s 340ms/step - loss: 2.6362 - en_loss: 0.9152 - es_loss: 0.9129 - cm_loss: 0.8081 - en_f1: 0.4861 - es_f1: 0.4765 - cm_f1: 0.5986 - val_loss: 3.0126 - val_en_loss: 1.0127 - val_es_loss: 1.0632 - val_cm_loss: 0.9367 - val_en_f1: 0.4200 - val_es_f1: 0.4239 - val_cm_f1: 0.5014\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 69s 343ms/step - loss: 2.5943 - en_loss: 0.9014 - es_loss: 0.9007 - cm_loss: 0.7921 - en_f1: 0.5134 - es_f1: 0.4923 - cm_f1: 0.6116 - val_loss: 2.9546 - val_en_loss: 1.0078 - val_es_loss: 1.0191 - val_cm_loss: 0.9277 - val_en_f1: 0.4081 - val_es_f1: 0.4276 - val_cm_f1: 0.5149\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 68s 340ms/step - loss: 2.6235 - en_loss: 0.9100 - es_loss: 0.9108 - cm_loss: 0.8027 - en_f1: 0.4805 - es_f1: 0.4837 - cm_f1: 0.5936 - val_loss: 2.9031 - val_en_loss: 0.9993 - val_es_loss: 0.9904 - val_cm_loss: 0.9134 - val_en_f1: 0.3716 - val_es_f1: 0.2885 - val_cm_f1: 0.4936\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 67s 333ms/step - loss: 2.5547 - en_loss: 0.8902 - es_loss: 0.8843 - cm_loss: 0.7802 - en_f1: 0.5149 - es_f1: 0.5106 - cm_f1: 0.6236 - val_loss: 2.8794 - val_en_loss: 0.9761 - val_es_loss: 0.9820 - val_cm_loss: 0.9213 - val_en_f1: 0.3882 - val_es_f1: 0.4193 - val_cm_f1: 0.4968\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 68s 341ms/step - loss: 2.5351 - en_loss: 0.8822 - es_loss: 0.8780 - cm_loss: 0.7749 - en_f1: 0.5196 - es_f1: 0.5124 - cm_f1: 0.6218 - val_loss: 2.9026 - val_en_loss: 1.0014 - val_es_loss: 0.9874 - val_cm_loss: 0.9138 - val_en_f1: 0.4101 - val_es_f1: 0.4275 - val_cm_f1: 0.5281\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 68s 341ms/step - loss: 2.4909 - en_loss: 0.8652 - es_loss: 0.8599 - cm_loss: 0.7658 - en_f1: 0.5240 - es_f1: 0.5453 - cm_f1: 0.6273 - val_loss: 2.8583 - val_en_loss: 0.9802 - val_es_loss: 0.9641 - val_cm_loss: 0.9141 - val_en_f1: 0.4322 - val_es_f1: 0.3544 - val_cm_f1: 0.5223\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 69s 345ms/step - loss: 2.4928 - en_loss: 0.8654 - es_loss: 0.8578 - cm_loss: 0.7696 - en_f1: 0.5326 - es_f1: 0.5480 - cm_f1: 0.6265 - val_loss: 2.8800 - val_en_loss: 0.9863 - val_es_loss: 0.9719 - val_cm_loss: 0.9218 - val_en_f1: 0.4835 - val_es_f1: 0.4578 - val_cm_f1: 0.5281\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 68s 341ms/step - loss: 2.4460 - en_loss: 0.8423 - es_loss: 0.8434 - cm_loss: 0.7603 - en_f1: 0.5701 - es_f1: 0.5739 - cm_f1: 0.6336 - val_loss: 2.8251 - val_en_loss: 0.9728 - val_es_loss: 0.9549 - val_cm_loss: 0.8973 - val_en_f1: 0.4373 - val_es_f1: 0.4128 - val_cm_f1: 0.5238\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 68s 342ms/step - loss: 2.4597 - en_loss: 0.8451 - es_loss: 0.8443 - cm_loss: 0.7703 - en_f1: 0.5533 - es_f1: 0.5500 - cm_f1: 0.6222 - val_loss: 2.8983 - val_en_loss: 1.0198 - val_es_loss: 0.9594 - val_cm_loss: 0.9190 - val_en_f1: 0.4512 - val_es_f1: 0.4796 - val_cm_f1: 0.5380\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 68s 342ms/step - loss: 2.4362 - en_loss: 0.8434 - es_loss: 0.8308 - cm_loss: 0.7620 - en_f1: 0.5734 - es_f1: 0.5871 - cm_f1: 0.6331 - val_loss: 2.8774 - val_en_loss: 0.9968 - val_es_loss: 0.9732 - val_cm_loss: 0.9074 - val_en_f1: 0.4892 - val_es_f1: 0.4652 - val_cm_f1: 0.5297\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 67s 333ms/step - loss: 2.4000 - en_loss: 0.8280 - es_loss: 0.8190 - cm_loss: 0.7531 - en_f1: 0.5710 - es_f1: 0.5918 - cm_f1: 0.6392 - val_loss: 2.8660 - val_en_loss: 0.9702 - val_es_loss: 0.9913 - val_cm_loss: 0.9045 - val_en_f1: 0.4366 - val_es_f1: 0.4774 - val_cm_f1: 0.5157\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 68s 338ms/step - loss: 2.3936 - en_loss: 0.8167 - es_loss: 0.8250 - cm_loss: 0.7520 - en_f1: 0.5755 - es_f1: 0.5798 - cm_f1: 0.6346 - val_loss: 2.8458 - val_en_loss: 0.9700 - val_es_loss: 0.9713 - val_cm_loss: 0.9046 - val_en_f1: 0.4616 - val_es_f1: 0.4748 - val_cm_f1: 0.5199\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 65s 324ms/step - loss: 2.3858 - en_loss: 0.8142 - es_loss: 0.8232 - cm_loss: 0.7484 - en_f1: 0.5878 - es_f1: 0.5804 - cm_f1: 0.6388 - val_loss: 2.8429 - val_en_loss: 0.9604 - val_es_loss: 0.9844 - val_cm_loss: 0.8981 - val_en_f1: 0.4880 - val_es_f1: 0.4760 - val_cm_f1: 0.5333\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 66s 331ms/step - loss: 2.3623 - en_loss: 0.8075 - es_loss: 0.8096 - cm_loss: 0.7452 - en_f1: 0.5981 - es_f1: 0.6021 - cm_f1: 0.6492 - val_loss: 2.9065 - val_en_loss: 1.0069 - val_es_loss: 0.9769 - val_cm_loss: 0.9227 - val_en_f1: 0.5009 - val_es_f1: 0.5129 - val_cm_f1: 0.5395\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 65s 324ms/step - loss: 2.3666 - en_loss: 0.8122 - es_loss: 0.8117 - cm_loss: 0.7427 - en_f1: 0.5986 - es_f1: 0.5916 - cm_f1: 0.6422 - val_loss: 2.9437 - val_en_loss: 0.9819 - val_es_loss: 1.0381 - val_cm_loss: 0.9237 - val_en_f1: 0.5037 - val_es_f1: 0.5116 - val_cm_f1: 0.5462\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 66s 329ms/step - loss: 2.3392 - en_loss: 0.7965 - es_loss: 0.8002 - cm_loss: 0.7425 - en_f1: 0.5990 - es_f1: 0.6064 - cm_f1: 0.6476 - val_loss: 2.8051 - val_en_loss: 0.9454 - val_es_loss: 0.9616 - val_cm_loss: 0.8981 - val_en_f1: 0.3582 - val_es_f1: 0.4327 - val_cm_f1: 0.5231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc06276ab70>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = train_generator(32, lang=\"en\")\n",
    "model.fit_generator(\n",
    "    generator=gen,\n",
    "    steps_per_epoch=200,\n",
    "    epochs=20,\n",
    "    initial_epoch=0,\n",
    "    validation_data=([en_es_x_train,en_es_x_train,en_es_x_train],[en_es_y_train,en_es_y_train,en_es_y_train]),\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6964681451900163,\n",
       " 0.9170048700654682,\n",
       " 0.9290861341537114,\n",
       " 0.8503770978960283,\n",
       " 0.4020865367053967,\n",
       " 0.4387365517375131,\n",
       " 0.5475156961607506]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([en_es_x_test,en_es_x_test,en_es_x_test],[en_es_y_test,en_es_y_test,en_es_y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "200/200 [==============================] - 68s 338ms/step - loss: 2.9453 - en_loss: 1.0016 - es_loss: 1.0021 - cm_loss: 0.9417 - en_f1: 0.3142 - es_f1: 0.3501 - cm_f1: 0.4229 - val_loss: 2.8113 - val_en_loss: 0.9546 - val_es_loss: 0.9576 - val_cm_loss: 0.8991 - val_en_f1: 0.4130 - val_es_f1: 0.3947 - val_cm_f1: 0.4260\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 66s 329ms/step - loss: 2.7575 - en_loss: 0.9381 - es_loss: 0.9374 - cm_loss: 0.8820 - en_f1: 0.4716 - es_f1: 0.4631 - cm_f1: 0.4975 - val_loss: 2.8606 - val_en_loss: 1.0016 - val_es_loss: 0.9598 - val_cm_loss: 0.8992 - val_en_f1: 0.4059 - val_es_f1: 0.4529 - val_cm_f1: 0.4514\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 66s 332ms/step - loss: 2.7297 - en_loss: 0.9259 - es_loss: 0.9332 - cm_loss: 0.8706 - en_f1: 0.4866 - es_f1: 0.4762 - cm_f1: 0.5275 - val_loss: 2.7456 - val_en_loss: 0.9297 - val_es_loss: 0.9305 - val_cm_loss: 0.8853 - val_en_f1: 0.4051 - val_es_f1: 0.4212 - val_cm_f1: 0.4846\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 67s 333ms/step - loss: 2.6788 - en_loss: 0.9103 - es_loss: 0.9159 - cm_loss: 0.8526 - en_f1: 0.4956 - es_f1: 0.4963 - cm_f1: 0.5506 - val_loss: 2.8395 - val_en_loss: 0.9648 - val_es_loss: 0.9664 - val_cm_loss: 0.9084 - val_en_f1: 0.4211 - val_es_f1: 0.4376 - val_cm_f1: 0.4724\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 67s 335ms/step - loss: 2.6375 - en_loss: 0.8962 - es_loss: 0.8982 - cm_loss: 0.8431 - en_f1: 0.5211 - es_f1: 0.5168 - cm_f1: 0.5657 - val_loss: 2.7566 - val_en_loss: 0.9331 - val_es_loss: 0.9399 - val_cm_loss: 0.8836 - val_en_f1: 0.4021 - val_es_f1: 0.4080 - val_cm_f1: 0.4906\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 2.6469 - en_loss: 0.9011 - es_loss: 0.9041 - cm_loss: 0.8417 - en_f1: 0.5015 - es_f1: 0.5025 - cm_f1: 0.5642 - val_loss: 2.7880 - val_en_loss: 0.9546 - val_es_loss: 0.9394 - val_cm_loss: 0.8940 - val_en_f1: 0.3936 - val_es_f1: 0.4225 - val_cm_f1: 0.4897\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 65s 324ms/step - loss: 2.6190 - en_loss: 0.8913 - es_loss: 0.8960 - cm_loss: 0.8318 - en_f1: 0.5263 - es_f1: 0.5080 - cm_f1: 0.5712 - val_loss: 2.7827 - val_en_loss: 0.9509 - val_es_loss: 0.9345 - val_cm_loss: 0.8974 - val_en_f1: 0.4293 - val_es_f1: 0.4242 - val_cm_f1: 0.4957\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 66s 332ms/step - loss: 2.5886 - en_loss: 0.8787 - es_loss: 0.8841 - cm_loss: 0.8257 - en_f1: 0.5345 - es_f1: 0.5228 - cm_f1: 0.5779 - val_loss: 2.7589 - val_en_loss: 0.9341 - val_es_loss: 0.9395 - val_cm_loss: 0.8853 - val_en_f1: 0.4052 - val_es_f1: 0.4303 - val_cm_f1: 0.5042\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 68s 340ms/step - loss: 2.5797 - en_loss: 0.8745 - es_loss: 0.8834 - cm_loss: 0.8218 - en_f1: 0.5324 - es_f1: 0.5219 - cm_f1: 0.5838 - val_loss: 2.7635 - val_en_loss: 0.9363 - val_es_loss: 0.9394 - val_cm_loss: 0.8879 - val_en_f1: 0.4430 - val_es_f1: 0.4339 - val_cm_f1: 0.5097\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 67s 336ms/step - loss: 2.5984 - en_loss: 0.8878 - es_loss: 0.8828 - cm_loss: 0.8278 - en_f1: 0.5143 - es_f1: 0.5203 - cm_f1: 0.5752 - val_loss: 2.7769 - val_en_loss: 0.9412 - val_es_loss: 0.9434 - val_cm_loss: 0.8923 - val_en_f1: 0.3823 - val_es_f1: 0.4065 - val_cm_f1: 0.4928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc06276ab38>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = train_generator(32, lang=\"es\")\n",
    "model.fit_generator(\n",
    "    generator=gen,\n",
    "    steps_per_epoch=200,\n",
    "    epochs=30,\n",
    "    initial_epoch=20,\n",
    "    validation_data=([en_es_x_train,en_es_x_train,en_es_x_train],[en_es_y_train,en_es_y_train,en_es_y_train]),\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.689742552709035,\n",
       " 0.9178007408417458,\n",
       " 0.9133689415202055,\n",
       " 0.8585728392320978,\n",
       " 0.40414127478980705,\n",
       " 0.4419087814273492,\n",
       " 0.49333386183951844]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([en_es_x_test,en_es_x_test,en_es_x_test],[en_es_y_test,en_es_y_test,en_es_y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 2.4814 - en_loss: 0.8266 - es_loss: 0.8731 - cm_loss: 0.7817 - en_f1: 0.5843 - es_f1: 0.5364 - cm_f1: 0.6149 - val_loss: 2.7216 - val_en_loss: 0.9239 - val_es_loss: 0.9237 - val_cm_loss: 0.8740 - val_en_f1: 0.4299 - val_es_f1: 0.4880 - val_cm_f1: 0.5205\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 65s 323ms/step - loss: 2.4406 - en_loss: 0.8194 - es_loss: 0.8597 - cm_loss: 0.7615 - en_f1: 0.5757 - es_f1: 0.5603 - cm_f1: 0.6347 - val_loss: 2.7314 - val_en_loss: 0.9118 - val_es_loss: 0.9405 - val_cm_loss: 0.8791 - val_en_f1: 0.4788 - val_es_f1: 0.4437 - val_cm_f1: 0.5111\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 66s 328ms/step - loss: 2.4382 - en_loss: 0.8002 - es_loss: 0.8738 - cm_loss: 0.7642 - en_f1: 0.5996 - es_f1: 0.5347 - cm_f1: 0.6255 - val_loss: 2.6985 - val_en_loss: 0.8929 - val_es_loss: 0.9321 - val_cm_loss: 0.8735 - val_en_f1: 0.5155 - val_es_f1: 0.4354 - val_cm_f1: 0.5300\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 66s 331ms/step - loss: 2.4274 - en_loss: 0.8114 - es_loss: 0.8609 - cm_loss: 0.7552 - en_f1: 0.5923 - es_f1: 0.5565 - cm_f1: 0.6373 - val_loss: 2.7014 - val_en_loss: 0.9067 - val_es_loss: 0.9194 - val_cm_loss: 0.8752 - val_en_f1: 0.4810 - val_es_f1: 0.4787 - val_cm_f1: 0.5162\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 66s 332ms/step - loss: 2.4093 - en_loss: 0.7909 - es_loss: 0.8518 - cm_loss: 0.7667 - en_f1: 0.6072 - es_f1: 0.5479 - cm_f1: 0.6309 - val_loss: 2.6819 - val_en_loss: 0.8953 - val_es_loss: 0.9171 - val_cm_loss: 0.8695 - val_en_f1: 0.5291 - val_es_f1: 0.5077 - val_cm_f1: 0.5367\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 67s 333ms/step - loss: 2.3960 - en_loss: 0.7773 - es_loss: 0.8583 - cm_loss: 0.7603 - en_f1: 0.6158 - es_f1: 0.5380 - cm_f1: 0.6352 - val_loss: 2.6804 - val_en_loss: 0.8987 - val_es_loss: 0.9101 - val_cm_loss: 0.8717 - val_en_f1: 0.4603 - val_es_f1: 0.4623 - val_cm_f1: 0.5260\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 67s 336ms/step - loss: 2.3923 - en_loss: 0.7877 - es_loss: 0.8602 - cm_loss: 0.7444 - en_f1: 0.6127 - es_f1: 0.5414 - cm_f1: 0.6421 - val_loss: 2.7077 - val_en_loss: 0.9001 - val_es_loss: 0.9209 - val_cm_loss: 0.8867 - val_en_f1: 0.4741 - val_es_f1: 0.4318 - val_cm_f1: 0.5189\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 69s 347ms/step - loss: 2.3908 - en_loss: 0.7888 - es_loss: 0.8410 - cm_loss: 0.7610 - en_f1: 0.6140 - es_f1: 0.5640 - cm_f1: 0.6296 - val_loss: 2.7010 - val_en_loss: 0.8949 - val_es_loss: 0.9322 - val_cm_loss: 0.8739 - val_en_f1: 0.4845 - val_es_f1: 0.4574 - val_cm_f1: 0.5145\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 69s 347ms/step - loss: 2.3799 - en_loss: 0.7697 - es_loss: 0.8619 - cm_loss: 0.7483 - en_f1: 0.6242 - es_f1: 0.5487 - cm_f1: 0.6339 - val_loss: 2.6781 - val_en_loss: 0.8975 - val_es_loss: 0.9056 - val_cm_loss: 0.8750 - val_en_f1: 0.4651 - val_es_f1: 0.4797 - val_cm_f1: 0.5218\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 69s 344ms/step - loss: 2.3739 - en_loss: 0.7804 - es_loss: 0.8533 - cm_loss: 0.7401 - en_f1: 0.6133 - es_f1: 0.5582 - cm_f1: 0.6415 - val_loss: 2.6905 - val_en_loss: 0.8950 - val_es_loss: 0.9199 - val_cm_loss: 0.8757 - val_en_f1: 0.5096 - val_es_f1: 0.5050 - val_cm_f1: 0.5250\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00040: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc06276a748>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = train_generator(32, lang=\"unsup\")\n",
    "model.fit_generator(\n",
    "    generator=gen,\n",
    "    steps_per_epoch=200,\n",
    "    epochs=50,\n",
    "    initial_epoch=30,\n",
    "    validation_data=([en_es_x_train,en_es_x_train,en_es_x_train],[en_es_y_train,en_es_y_train,en_es_y_train]),\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5449744120702076,\n",
       " 0.850822454661763,\n",
       " 0.8713245127368323,\n",
       " 0.8228274669382739,\n",
       " 0.5723932583802676,\n",
       " 0.5343010656985334,\n",
       " 0.5705737851766739]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([en_es_x_test,en_es_x_test,en_es_x_test],[en_es_y_test,en_es_y_test,en_es_y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/75\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 2.4788 - en_loss: 0.7693 - es_loss: 0.8659 - cm_loss: 0.8437 - en_f1: 0.6241 - es_f1: 0.5534 - cm_f1: 0.5659 - val_loss: 2.5210 - val_en_loss: 0.8522 - val_es_loss: 0.8809 - val_cm_loss: 0.7879 - val_en_f1: 0.5325 - val_es_f1: 0.5097 - val_cm_f1: 0.5923\n",
      "Epoch 52/75\n",
      "200/200 [==============================] - 62s 312ms/step - loss: 2.4723 - en_loss: 0.7903 - es_loss: 0.8596 - cm_loss: 0.8224 - en_f1: 0.6079 - es_f1: 0.5536 - cm_f1: 0.5903 - val_loss: 2.5234 - val_en_loss: 0.8709 - val_es_loss: 0.8868 - val_cm_loss: 0.7658 - val_en_f1: 0.5807 - val_es_f1: 0.4860 - val_cm_f1: 0.6427\n",
      "Epoch 53/75\n",
      "200/200 [==============================] - 63s 313ms/step - loss: 2.4573 - en_loss: 0.7997 - es_loss: 0.8523 - cm_loss: 0.8054 - en_f1: 0.6049 - es_f1: 0.5596 - cm_f1: 0.5991 - val_loss: 2.5012 - val_en_loss: 0.8501 - val_es_loss: 0.8950 - val_cm_loss: 0.7562 - val_en_f1: 0.5459 - val_es_f1: 0.4950 - val_cm_f1: 0.6439\n",
      "Epoch 54/75\n",
      "200/200 [==============================] - 62s 309ms/step - loss: 2.3889 - en_loss: 0.7723 - es_loss: 0.8554 - cm_loss: 0.7612 - en_f1: 0.6247 - es_f1: 0.5529 - cm_f1: 0.6393 - val_loss: 2.5117 - val_en_loss: 0.8516 - val_es_loss: 0.9032 - val_cm_loss: 0.7569 - val_en_f1: 0.5402 - val_es_f1: 0.4508 - val_cm_f1: 0.6415\n",
      "Epoch 55/75\n",
      "200/200 [==============================] - 61s 307ms/step - loss: 2.3892 - en_loss: 0.7750 - es_loss: 0.8430 - cm_loss: 0.7711 - en_f1: 0.6183 - es_f1: 0.5622 - cm_f1: 0.6333 - val_loss: 2.4836 - val_en_loss: 0.8514 - val_es_loss: 0.8731 - val_cm_loss: 0.7591 - val_en_f1: 0.5379 - val_es_f1: 0.5117 - val_cm_f1: 0.6393\n",
      "Epoch 56/75\n",
      "200/200 [==============================] - 62s 309ms/step - loss: 2.3615 - en_loss: 0.7554 - es_loss: 0.8490 - cm_loss: 0.7570 - en_f1: 0.6361 - es_f1: 0.5647 - cm_f1: 0.6418 - val_loss: 2.4551 - val_en_loss: 0.8485 - val_es_loss: 0.8535 - val_cm_loss: 0.7531 - val_en_f1: 0.5279 - val_es_f1: 0.5448 - val_cm_f1: 0.6498\n",
      "Epoch 57/75\n",
      "200/200 [==============================] - 61s 306ms/step - loss: 2.3482 - en_loss: 0.7541 - es_loss: 0.8378 - cm_loss: 0.7562 - en_f1: 0.6345 - es_f1: 0.5708 - cm_f1: 0.6518 - val_loss: 2.4573 - val_en_loss: 0.8385 - val_es_loss: 0.8726 - val_cm_loss: 0.7462 - val_en_f1: 0.5770 - val_es_f1: 0.5138 - val_cm_f1: 0.6594\n",
      "Epoch 58/75\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 2.3298 - en_loss: 0.7723 - es_loss: 0.8195 - cm_loss: 0.7380 - en_f1: 0.6248 - es_f1: 0.5940 - cm_f1: 0.6591 - val_loss: 2.4589 - val_en_loss: 0.8390 - val_es_loss: 0.8608 - val_cm_loss: 0.7592 - val_en_f1: 0.5352 - val_es_f1: 0.5551 - val_cm_f1: 0.6473\n",
      "Epoch 59/75\n",
      "200/200 [==============================] - 63s 314ms/step - loss: 2.3006 - en_loss: 0.7456 - es_loss: 0.8334 - cm_loss: 0.7215 - en_f1: 0.6425 - es_f1: 0.5746 - cm_f1: 0.6711 - val_loss: 2.4601 - val_en_loss: 0.8339 - val_es_loss: 0.8760 - val_cm_loss: 0.7502 - val_en_f1: 0.5348 - val_es_f1: 0.5359 - val_cm_f1: 0.6485\n",
      "Epoch 60/75\n",
      "200/200 [==============================] - 62s 309ms/step - loss: 2.3169 - en_loss: 0.7772 - es_loss: 0.8360 - cm_loss: 0.7037 - en_f1: 0.6119 - es_f1: 0.5724 - cm_f1: 0.6758 - val_loss: 2.4370 - val_en_loss: 0.8372 - val_es_loss: 0.8568 - val_cm_loss: 0.7430 - val_en_f1: 0.5311 - val_es_f1: 0.5462 - val_cm_f1: 0.6556\n",
      "Epoch 61/75\n",
      "200/200 [==============================] - 61s 306ms/step - loss: 2.2846 - en_loss: 0.7665 - es_loss: 0.8280 - cm_loss: 0.6900 - en_f1: 0.6263 - es_f1: 0.5752 - cm_f1: 0.6922 - val_loss: 2.4875 - val_en_loss: 0.8485 - val_es_loss: 0.8952 - val_cm_loss: 0.7438 - val_en_f1: 0.5576 - val_es_f1: 0.5041 - val_cm_f1: 0.6422\n",
      "Epoch 62/75\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 2.2580 - en_loss: 0.7534 - es_loss: 0.8325 - cm_loss: 0.6721 - en_f1: 0.6301 - es_f1: 0.5724 - cm_f1: 0.7027 - val_loss: 2.4901 - val_en_loss: 0.8419 - val_es_loss: 0.8943 - val_cm_loss: 0.7539 - val_en_f1: 0.5361 - val_es_f1: 0.4974 - val_cm_f1: 0.6387\n",
      "Epoch 63/75\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 2.2089 - en_loss: 0.7530 - es_loss: 0.8081 - cm_loss: 0.6478 - en_f1: 0.6316 - es_f1: 0.5958 - cm_f1: 0.7166 - val_loss: 2.4951 - val_en_loss: 0.8302 - val_es_loss: 0.9192 - val_cm_loss: 0.7458 - val_en_f1: 0.5527 - val_es_f1: 0.5215 - val_cm_f1: 0.6657\n",
      "Epoch 64/75\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 2.2127 - en_loss: 0.7509 - es_loss: 0.8048 - cm_loss: 0.6570 - en_f1: 0.6406 - es_f1: 0.6069 - cm_f1: 0.7079 - val_loss: 2.4478 - val_en_loss: 0.8308 - val_es_loss: 0.8734 - val_cm_loss: 0.7436 - val_en_f1: 0.5665 - val_es_f1: 0.5273 - val_cm_f1: 0.6695\n",
      "Epoch 65/75\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 2.2147 - en_loss: 0.7572 - es_loss: 0.8162 - cm_loss: 0.6413 - en_f1: 0.6320 - es_f1: 0.5868 - cm_f1: 0.7183 - val_loss: 2.4693 - val_en_loss: 0.8450 - val_es_loss: 0.8786 - val_cm_loss: 0.7457 - val_en_f1: 0.5174 - val_es_f1: 0.5417 - val_cm_f1: 0.6663\n",
      "Epoch 66/75\n",
      "200/200 [==============================] - 60s 300ms/step - loss: 2.2140 - en_loss: 0.7510 - es_loss: 0.8050 - cm_loss: 0.6581 - en_f1: 0.6340 - es_f1: 0.5966 - cm_f1: 0.7076 - val_loss: 2.4853 - val_en_loss: 0.8404 - val_es_loss: 0.8809 - val_cm_loss: 0.7641 - val_en_f1: 0.5634 - val_es_f1: 0.5148 - val_cm_f1: 0.6572\n",
      "Epoch 67/75\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 2.1891 - en_loss: 0.7457 - es_loss: 0.8116 - cm_loss: 0.6318 - en_f1: 0.6453 - es_f1: 0.5874 - cm_f1: 0.7242 - val_loss: 2.4748 - val_en_loss: 0.8376 - val_es_loss: 0.8810 - val_cm_loss: 0.7562 - val_en_f1: 0.5477 - val_es_f1: 0.5276 - val_cm_f1: 0.6706\n",
      "Epoch 68/75\n",
      "200/200 [==============================] - 59s 296ms/step - loss: 2.1546 - en_loss: 0.7252 - es_loss: 0.8133 - cm_loss: 0.6160 - en_f1: 0.6516 - es_f1: 0.5912 - cm_f1: 0.7340 - val_loss: 2.5026 - val_en_loss: 0.8281 - val_es_loss: 0.9189 - val_cm_loss: 0.7556 - val_en_f1: 0.5724 - val_es_f1: 0.4965 - val_cm_f1: 0.6648\n",
      "Epoch 69/75\n",
      "200/200 [==============================] - 60s 301ms/step - loss: 2.1330 - en_loss: 0.7412 - es_loss: 0.7909 - cm_loss: 0.6009 - en_f1: 0.6483 - es_f1: 0.6091 - cm_f1: 0.7397 - val_loss: 2.5099 - val_en_loss: 0.8225 - val_es_loss: 0.8989 - val_cm_loss: 0.7885 - val_en_f1: 0.5616 - val_es_f1: 0.4969 - val_cm_f1: 0.6639\n",
      "Epoch 70/75\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 2.1352 - en_loss: 0.7493 - es_loss: 0.7843 - cm_loss: 0.6015 - en_f1: 0.6393 - es_f1: 0.6113 - cm_f1: 0.7424 - val_loss: 2.4890 - val_en_loss: 0.8272 - val_es_loss: 0.8757 - val_cm_loss: 0.7861 - val_en_f1: 0.5299 - val_es_f1: 0.5365 - val_cm_f1: 0.6638\n",
      "Epoch 71/75\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 2.1292 - en_loss: 0.7417 - es_loss: 0.7910 - cm_loss: 0.5965 - en_f1: 0.6356 - es_f1: 0.6043 - cm_f1: 0.7451 - val_loss: 2.5362 - val_en_loss: 0.8367 - val_es_loss: 0.8854 - val_cm_loss: 0.8141 - val_en_f1: 0.5130 - val_es_f1: 0.5261 - val_cm_f1: 0.6524\n",
      "Epoch 72/75\n",
      "200/200 [==============================] - 61s 305ms/step - loss: 2.0864 - en_loss: 0.7448 - es_loss: 0.7798 - cm_loss: 0.5618 - en_f1: 0.6413 - es_f1: 0.6155 - cm_f1: 0.7680 - val_loss: 2.5384 - val_en_loss: 0.8222 - val_es_loss: 0.9245 - val_cm_loss: 0.7917 - val_en_f1: 0.5466 - val_es_f1: 0.5588 - val_cm_f1: 0.6564\n",
      "Epoch 73/75\n",
      "200/200 [==============================] - 61s 306ms/step - loss: 2.1079 - en_loss: 0.7517 - es_loss: 0.7846 - cm_loss: 0.5716 - en_f1: 0.6321 - es_f1: 0.6141 - cm_f1: 0.7575 - val_loss: 2.5172 - val_en_loss: 0.8293 - val_es_loss: 0.9087 - val_cm_loss: 0.7792 - val_en_f1: 0.5139 - val_es_f1: 0.5468 - val_cm_f1: 0.6640\n",
      "Epoch 74/75\n",
      "200/200 [==============================] - 63s 315ms/step - loss: 2.0804 - en_loss: 0.7343 - es_loss: 0.7815 - cm_loss: 0.5646 - en_f1: 0.6475 - es_f1: 0.6165 - cm_f1: 0.7605 - val_loss: 2.5456 - val_en_loss: 0.8294 - val_es_loss: 0.9069 - val_cm_loss: 0.8093 - val_en_f1: 0.5539 - val_es_f1: 0.5482 - val_cm_f1: 0.6703\n",
      "Epoch 75/75\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 2.0676 - en_loss: 0.7330 - es_loss: 0.7681 - cm_loss: 0.5666 - en_f1: 0.6458 - es_f1: 0.6289 - cm_f1: 0.7562 - val_loss: 2.5120 - val_en_loss: 0.8258 - val_es_loss: 0.8895 - val_cm_loss: 0.7967 - val_en_f1: 0.5720 - val_es_f1: 0.5458 - val_cm_f1: 0.6658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc06276aa20>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = train_generator(32)\n",
    "model.fit_generator(\n",
    "    generator=gen,\n",
    "    steps_per_epoch=200,\n",
    "    epochs=75,\n",
    "    initial_epoch=50,\n",
    "    validation_data=([en_es_x_test,en_es_x_test,en_es_x_test],[en_es_y_test,en_es_y_test,en_es_y_test])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5119908143801166,\n",
       " 0.8257767659221543,\n",
       " 0.8894732844382282,\n",
       " 0.7967407826887258,\n",
       " 0.5720008315114368,\n",
       " 0.5457861570316271,\n",
       " 0.6657662629886708]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([en_es_x_test,en_es_x_test,en_es_x_test],[en_es_y_test,en_es_y_test,en_es_y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ! pip3 install keras-self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hindi English Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/IIITH_Codemixed.txt\") as f:\n",
    "    lines = f.readlines()[:-1]\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = {\"0\":-1 , \"1\" :1 , \"2\":0}\n",
    "data = map( lambda x : x.strip().split(\"\\t\") , lines )\n",
    "data = map( lambda x :{'sentiment': sents[x[3]] , 'text': x[1] } , data )\n",
    "hi_en_data = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [x['text'] for x in hi_en_data]\n",
    "y_train = [x['sentiment'] for x in hi_en_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32\n",
    "zero_vector = [0 for _ in range(300)]\n",
    "def get_x(data_):\n",
    "    x_  = []\n",
    "    for sent in data_:\n",
    "        pred = list(multibpemb.embed(sent))\n",
    "        if len(pred) >= 32:\n",
    "            pred = pred[:32]\n",
    "        else:\n",
    "            counter = len(pred)\n",
    "            while counter < max_len:\n",
    "                pred.append(zero_vector)\n",
    "                counter = counter + 1\n",
    "        x_.append(pred)\n",
    "    return np.array(x_)\n",
    "X_train =  get_x(X_train)\n",
    "X_test = get_x(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
