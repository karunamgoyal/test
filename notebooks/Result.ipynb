{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# important setup\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utills import read_data,f1\n",
    "from models import get_seq_model, get_dense_model\n",
    "from trainer import train\n",
    "from data_prep import SentimentData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = SentimentData.read_raw(\"../data/cm/train.txt\",\"../data/cm/test.txt\")\n",
    "data.apply_fasttext(\"../data/fastTextEmbed/combined_mono_cm.bin\")\n",
    "data.save(\"../data/ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SentimentData.read_pickle(\"../data/ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 60,703\n",
      "Trainable params: 60,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_seq_model()\n",
    "model.build(input_shape=(None,32,100))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on concat\n",
      "Train on 35292 samples, validate on 2449 samples\n",
      "Epoch 1/100\n",
      "  160/35292 [..............................] - ETA: 28:34 - loss: 1.0424 - accuracy: 0.5312 - f1: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (2.628043). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.245836). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.124243). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35292/35292 [==============================] - 78s 2ms/step - loss: 0.9471 - accuracy: 0.5326 - f1: 0.4223 - val_loss: 0.9802 - val_accuracy: 0.5063 - val_f1: 0.3424\n",
      "Epoch 2/100\n",
      "35292/35292 [==============================] - 69s 2ms/step - loss: 0.8928 - accuracy: 0.5717 - f1: 0.5125 - val_loss: 0.9542 - val_accuracy: 0.5329 - val_f1: 0.3654\n",
      "Epoch 3/100\n",
      "35292/35292 [==============================] - 70s 2ms/step - loss: 0.8685 - accuracy: 0.5864 - f1: 0.5340 - val_loss: 0.9311 - val_accuracy: 0.5590 - val_f1: 0.4285\n",
      "Epoch 4/100\n",
      "35292/35292 [==============================] - 69s 2ms/step - loss: 0.8428 - accuracy: 0.6055 - f1: 0.5625 - val_loss: 0.9274 - val_accuracy: 0.5655 - val_f1: 0.4334\n",
      "Epoch 5/100\n",
      "35292/35292 [==============================] - 69s 2ms/step - loss: 0.8282 - accuracy: 0.6138 - f1: 0.5728 - val_loss: 0.9142 - val_accuracy: 0.5762 - val_f1: 0.4895\n",
      "Epoch 6/100\n",
      "35292/35292 [==============================] - 70s 2ms/step - loss: 0.8127 - accuracy: 0.6224 - f1: 0.5896 - val_loss: 0.9070 - val_accuracy: 0.5811 - val_f1: 0.4671\n",
      "Epoch 7/100\n",
      "35292/35292 [==============================] - 71s 2ms/step - loss: 0.8034 - accuracy: 0.6301 - f1: 0.5965 - val_loss: 0.8970 - val_accuracy: 0.5884 - val_f1: 0.4837\n",
      "Epoch 8/100\n",
      "35292/35292 [==============================] - 70s 2ms/step - loss: 0.7950 - accuracy: 0.6328 - f1: 0.6016 - val_loss: 0.8944 - val_accuracy: 0.5786 - val_f1: 0.4979\n",
      "Epoch 9/100\n",
      "35292/35292 [==============================] - 71s 2ms/step - loss: 0.7870 - accuracy: 0.6378 - f1: 0.6075 - val_loss: 0.8934 - val_accuracy: 0.5872 - val_f1: 0.5194\n",
      "Epoch 10/100\n",
      "35292/35292 [==============================] - 72s 2ms/step - loss: 0.7800 - accuracy: 0.6422 - f1: 0.6139 - val_loss: 0.8828 - val_accuracy: 0.6023 - val_f1: 0.5125\n",
      "Epoch 11/100\n",
      "35292/35292 [==============================] - 73s 2ms/step - loss: 0.7748 - accuracy: 0.6452 - f1: 0.6205 - val_loss: 0.8973 - val_accuracy: 0.5827 - val_f1: 0.4814\n",
      "Epoch 12/100\n",
      "35292/35292 [==============================] - 74s 2ms/step - loss: 0.7679 - accuracy: 0.6489 - f1: 0.6212 - val_loss: 0.8924 - val_accuracy: 0.5766 - val_f1: 0.4862\n",
      "Epoch 13/100\n",
      "35292/35292 [==============================] - 73s 2ms/step - loss: 0.7617 - accuracy: 0.6543 - f1: 0.6271 - val_loss: 0.8814 - val_accuracy: 0.6002 - val_f1: 0.5178\n",
      "Epoch 14/100\n",
      "35292/35292 [==============================] - 73s 2ms/step - loss: 0.7571 - accuracy: 0.6567 - f1: 0.6297 - val_loss: 0.8756 - val_accuracy: 0.6109 - val_f1: 0.5205\n",
      "Epoch 15/100\n",
      "35292/35292 [==============================] - 73s 2ms/step - loss: 0.7515 - accuracy: 0.6605 - f1: 0.6368 - val_loss: 0.8719 - val_accuracy: 0.6056 - val_f1: 0.5357\n",
      "Epoch 16/100\n",
      "35292/35292 [==============================] - 73s 2ms/step - loss: 0.7447 - accuracy: 0.6651 - f1: 0.6392 - val_loss: 0.8967 - val_accuracy: 0.5623 - val_f1: 0.4929\n",
      "Epoch 17/100\n",
      "35292/35292 [==============================] - 71s 2ms/step - loss: 0.7425 - accuracy: 0.6634 - f1: 0.6416 - val_loss: 0.8727 - val_accuracy: 0.6096 - val_f1: 0.5115\n",
      "Epoch 18/100\n",
      "35292/35292 [==============================] - 73s 2ms/step - loss: 0.7414 - accuracy: 0.6671 - f1: 0.6437 - val_loss: 0.8769 - val_accuracy: 0.5986 - val_f1: 0.5392\n",
      "Epoch 19/100\n",
      "35292/35292 [==============================] - 73s 2ms/step - loss: 0.7339 - accuracy: 0.6672 - f1: 0.6471 - val_loss: 0.8953 - val_accuracy: 0.5847 - val_f1: 0.5301\n",
      "Epoch 20/100\n",
      "35292/35292 [==============================] - 72s 2ms/step - loss: 0.7298 - accuracy: 0.6698 - f1: 0.6475 - val_loss: 0.8628 - val_accuracy: 0.6174 - val_f1: 0.5540\n",
      "Epoch 21/100\n",
      "35292/35292 [==============================] - 72s 2ms/step - loss: 0.7236 - accuracy: 0.6740 - f1: 0.6553 - val_loss: 0.8661 - val_accuracy: 0.5986 - val_f1: 0.5358\n",
      "Epoch 22/100\n",
      "35292/35292 [==============================] - 71s 2ms/step - loss: 0.7191 - accuracy: 0.6772 - f1: 0.6572 - val_loss: 0.8784 - val_accuracy: 0.5872 - val_f1: 0.5321\n",
      "Epoch 23/100\n",
      "35292/35292 [==============================] - 70s 2ms/step - loss: 0.7181 - accuracy: 0.6796 - f1: 0.6601 - val_loss: 0.8688 - val_accuracy: 0.6047 - val_f1: 0.5398\n",
      "Epoch 24/100\n",
      "35292/35292 [==============================] - 70s 2ms/step - loss: 0.7146 - accuracy: 0.6776 - f1: 0.6579 - val_loss: 0.8967 - val_accuracy: 0.5721 - val_f1: 0.5205\n",
      "Epoch 25/100\n",
      "35292/35292 [==============================] - 69s 2ms/step - loss: 0.7115 - accuracy: 0.6816 - f1: 0.6636 - val_loss: 0.8883 - val_accuracy: 0.5962 - val_f1: 0.5421\n",
      "Epoch 26/100\n",
      "35292/35292 [==============================] - 70s 2ms/step - loss: 0.7080 - accuracy: 0.6817 - f1: 0.6633 - val_loss: 0.8611 - val_accuracy: 0.6031 - val_f1: 0.5459\n",
      "Epoch 27/100\n",
      "35292/35292 [==============================] - 69s 2ms/step - loss: 0.7031 - accuracy: 0.6864 - f1: 0.6691 - val_loss: 0.8984 - val_accuracy: 0.5745 - val_f1: 0.4973\n",
      "Epoch 28/100\n",
      "35292/35292 [==============================] - 69s 2ms/step - loss: 0.6997 - accuracy: 0.6896 - f1: 0.6724 - val_loss: 0.8856 - val_accuracy: 0.5798 - val_f1: 0.5232\n",
      "Epoch 29/100\n",
      "35292/35292 [==============================] - 70s 2ms/step - loss: 0.6984 - accuracy: 0.6893 - f1: 0.6707 - val_loss: 0.8962 - val_accuracy: 0.5835 - val_f1: 0.5216\n",
      "Epoch 30/100\n",
      "35292/35292 [==============================] - 68s 2ms/step - loss: 0.6972 - accuracy: 0.6840 - f1: 0.6681 - val_loss: 0.8561 - val_accuracy: 0.6056 - val_f1: 0.5472\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00030: early stopping\n",
      "613/613 [==============================] - 0s 743us/step\n",
      "{'both': [0.8201249163555282, 0.6280587315559387, 0.5840260982513428]}\n",
      "Training on cm\n",
      "Train on 1959 samples, validate on 490 samples\n",
      "Epoch 51/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.9022 - accuracy: 0.5850 - f1: 0.5309 - val_loss: 0.8234 - val_accuracy: 0.6082 - val_f1: 0.5698\n",
      "Epoch 52/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.8596 - accuracy: 0.6049 - f1: 0.5550 - val_loss: 0.8068 - val_accuracy: 0.6082 - val_f1: 0.5899\n",
      "Epoch 53/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.8219 - accuracy: 0.6212 - f1: 0.5785 - val_loss: 0.7962 - val_accuracy: 0.6327 - val_f1: 0.6006\n",
      "Epoch 54/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.8106 - accuracy: 0.6320 - f1: 0.6032 - val_loss: 0.7923 - val_accuracy: 0.6429 - val_f1: 0.6011\n",
      "Epoch 55/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.7836 - accuracy: 0.6621 - f1: 0.6283 - val_loss: 0.7919 - val_accuracy: 0.6184 - val_f1: 0.6020\n",
      "Epoch 56/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.7796 - accuracy: 0.6559 - f1: 0.6257 - val_loss: 0.7845 - val_accuracy: 0.6327 - val_f1: 0.6197\n",
      "Epoch 57/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.7520 - accuracy: 0.6697 - f1: 0.6422 - val_loss: 0.7786 - val_accuracy: 0.6551 - val_f1: 0.6284\n",
      "Epoch 58/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.7409 - accuracy: 0.6764 - f1: 0.6538 - val_loss: 0.7704 - val_accuracy: 0.6571 - val_f1: 0.6381\n",
      "Epoch 59/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.7344 - accuracy: 0.6845 - f1: 0.6557 - val_loss: 0.7701 - val_accuracy: 0.6571 - val_f1: 0.6359\n",
      "Epoch 60/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.7151 - accuracy: 0.6937 - f1: 0.6743 - val_loss: 0.7708 - val_accuracy: 0.6531 - val_f1: 0.6317\n",
      "Epoch 61/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.7307 - accuracy: 0.6835 - f1: 0.6587 - val_loss: 0.7636 - val_accuracy: 0.6633 - val_f1: 0.6333\n",
      "Epoch 62/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.6986 - accuracy: 0.6958 - f1: 0.6742 - val_loss: 0.7682 - val_accuracy: 0.6592 - val_f1: 0.6376\n",
      "Epoch 63/70\n",
      "1959/1959 [==============================] - 5s 2ms/step - loss: 0.7029 - accuracy: 0.6891 - f1: 0.6696 - val_loss: 0.7755 - val_accuracy: 0.6490 - val_f1: 0.6246\n",
      "Epoch 64/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.6744 - accuracy: 0.7070 - f1: 0.6979 - val_loss: 0.7784 - val_accuracy: 0.6449 - val_f1: 0.6317\n",
      "Epoch 65/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.6703 - accuracy: 0.7141 - f1: 0.6975 - val_loss: 0.7557 - val_accuracy: 0.6633 - val_f1: 0.6350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.6508 - accuracy: 0.7203 - f1: 0.7065 - val_loss: 0.7509 - val_accuracy: 0.6592 - val_f1: 0.6459\n",
      "Epoch 67/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.6698 - accuracy: 0.7249 - f1: 0.7107 - val_loss: 0.7650 - val_accuracy: 0.6551 - val_f1: 0.6370\n",
      "Epoch 68/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.6513 - accuracy: 0.7223 - f1: 0.7108 - val_loss: 0.7590 - val_accuracy: 0.6612 - val_f1: 0.6419\n",
      "Epoch 69/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.6244 - accuracy: 0.7351 - f1: 0.7269 - val_loss: 0.7800 - val_accuracy: 0.6510 - val_f1: 0.6482\n",
      "Epoch 70/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.6326 - accuracy: 0.7264 - f1: 0.7133 - val_loss: 0.7662 - val_accuracy: 0.6694 - val_f1: 0.6433\n",
      "613/613 [==============================] - 0s 734us/step\n",
      "{'both': [0.8201249163555282, 0.6280587315559387, 0.5840260982513428], 'cm': [0.755718238882684, 0.6949428915977478, 0.6771647334098816]}\n"
     ]
    }
   ],
   "source": [
    "model, metrics = train(model,data,\"fasttext_ct_concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'both': [0.8201249163555282, 0.6280587315559387, 0.5840260982513428],\n",
       " 'cm': [0.755718238882684, 0.6949428915977478, 0.6771647334098816]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultBPEmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SentimentData.read_raw(\"../data/cm/train.txt\",\"../data/cm/test.txt\")\n",
    "data.apply_multibpe()\n",
    "data.save(\"../data/mtlitbpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SentimentData.read_pickle(\"../data/mtlitbpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_2 (Bidirection (None, 100)               140400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 140,703\n",
      "Trainable params: 140,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_seq_model()\n",
    "model.build(input_shape=(None,32,300))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on concat\n",
      "Train on 35292 samples, validate on 2449 samples\n",
      "Epoch 1/100\n",
      "  128/35292 [..............................] - ETA: 1:32:35 - loss: 1.0827 - accuracy: 0.3203 - f1: 0.0421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (7.423686). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35292/35292 [==============================] - 96s 3ms/step - loss: 0.9441 - accuracy: 0.5335 - f1: 0.4335 - val_loss: 1.0417 - val_accuracy: 0.4594 - val_f1: 0.3159\n",
      "Epoch 2/100\n",
      "35292/35292 [==============================] - 76s 2ms/step - loss: 0.8629 - accuracy: 0.5923 - f1: 0.5395 - val_loss: 0.9970 - val_accuracy: 0.4969 - val_f1: 0.3623\n",
      "Epoch 3/100\n",
      "35292/35292 [==============================] - 76s 2ms/step - loss: 0.8210 - accuracy: 0.6186 - f1: 0.5780 - val_loss: 0.9830 - val_accuracy: 0.5214 - val_f1: 0.4360\n",
      "Epoch 4/100\n",
      "35292/35292 [==============================] - 75s 2ms/step - loss: 0.7917 - accuracy: 0.6365 - f1: 0.6038 - val_loss: 0.9708 - val_accuracy: 0.5198 - val_f1: 0.4382\n",
      "Epoch 5/100\n",
      "35292/35292 [==============================] - 75s 2ms/step - loss: 0.7639 - accuracy: 0.6531 - f1: 0.6248 - val_loss: 0.9722 - val_accuracy: 0.5263 - val_f1: 0.4633\n",
      "Epoch 6/100\n",
      "35292/35292 [==============================] - 76s 2ms/step - loss: 0.7410 - accuracy: 0.6678 - f1: 0.6438 - val_loss: 0.9599 - val_accuracy: 0.5325 - val_f1: 0.4553\n",
      "Epoch 7/100\n",
      "35292/35292 [==============================] - 73s 2ms/step - loss: 0.7117 - accuracy: 0.6841 - f1: 0.6649 - val_loss: 0.9458 - val_accuracy: 0.5451 - val_f1: 0.4757\n",
      "Epoch 8/100\n",
      "35292/35292 [==============================] - 74s 2ms/step - loss: 0.6878 - accuracy: 0.6944 - f1: 0.6757 - val_loss: 0.9613 - val_accuracy: 0.5443 - val_f1: 0.4796\n",
      "Epoch 9/100\n",
      "35292/35292 [==============================] - 73s 2ms/step - loss: 0.6649 - accuracy: 0.7098 - f1: 0.6923 - val_loss: 0.9670 - val_accuracy: 0.5414 - val_f1: 0.4748\n",
      "Epoch 10/100\n",
      "35292/35292 [==============================] - 73s 2ms/step - loss: 0.6423 - accuracy: 0.7201 - f1: 0.7059 - val_loss: 0.9803 - val_accuracy: 0.5455 - val_f1: 0.5098\n",
      "Epoch 11/100\n",
      "35292/35292 [==============================] - 72s 2ms/step - loss: 0.6257 - accuracy: 0.7293 - f1: 0.7159 - val_loss: 0.9812 - val_accuracy: 0.5361 - val_f1: 0.4964\n",
      "Epoch 12/100\n",
      "35292/35292 [==============================] - 72s 2ms/step - loss: 0.6062 - accuracy: 0.7402 - f1: 0.7288 - val_loss: 0.9838 - val_accuracy: 0.5325 - val_f1: 0.4989\n",
      "Epoch 13/100\n",
      "35292/35292 [==============================] - 72s 2ms/step - loss: 0.5861 - accuracy: 0.7497 - f1: 0.7378 - val_loss: 1.0099 - val_accuracy: 0.5386 - val_f1: 0.4957\n",
      "Epoch 14/100\n",
      "35292/35292 [==============================] - 72s 2ms/step - loss: 0.5731 - accuracy: 0.7574 - f1: 0.7479 - val_loss: 1.0328 - val_accuracy: 0.5276 - val_f1: 0.4922\n",
      "Epoch 15/100\n",
      "35292/35292 [==============================] - 73s 2ms/step - loss: 0.5562 - accuracy: 0.7655 - f1: 0.7578 - val_loss: 1.0524 - val_accuracy: 0.5223 - val_f1: 0.4979\n",
      "Epoch 16/100\n",
      "35292/35292 [==============================] - 71s 2ms/step - loss: 0.5442 - accuracy: 0.7686 - f1: 0.7613 - val_loss: 1.0269 - val_accuracy: 0.5386 - val_f1: 0.5115\n",
      "Epoch 17/100\n",
      "35292/35292 [==============================] - 75s 2ms/step - loss: 0.5326 - accuracy: 0.7739 - f1: 0.7671 - val_loss: 1.0480 - val_accuracy: 0.5419 - val_f1: 0.5085\n",
      "Epoch 18/100\n",
      "35292/35292 [==============================] - 75s 2ms/step - loss: 0.5203 - accuracy: 0.7802 - f1: 0.7737 - val_loss: 1.0697 - val_accuracy: 0.5337 - val_f1: 0.5025\n",
      "Epoch 19/100\n",
      "35292/35292 [==============================] - 74s 2ms/step - loss: 0.5120 - accuracy: 0.7824 - f1: 0.7777 - val_loss: 1.0624 - val_accuracy: 0.5374 - val_f1: 0.5111\n",
      "Epoch 20/100\n",
      "35292/35292 [==============================] - 75s 2ms/step - loss: 0.5055 - accuracy: 0.7897 - f1: 0.7848 - val_loss: 1.0684 - val_accuracy: 0.5414 - val_f1: 0.5146\n",
      "Epoch 21/100\n",
      "35292/35292 [==============================] - 74s 2ms/step - loss: 0.4948 - accuracy: 0.7926 - f1: 0.7882 - val_loss: 1.1062 - val_accuracy: 0.5243 - val_f1: 0.4934\n",
      "Epoch 22/100\n",
      "35292/35292 [==============================] - 73s 2ms/step - loss: 0.4846 - accuracy: 0.7964 - f1: 0.7926 - val_loss: 1.0968 - val_accuracy: 0.5308 - val_f1: 0.5066\n",
      "Epoch 23/100\n",
      "35292/35292 [==============================] - 71s 2ms/step - loss: 0.4787 - accuracy: 0.7978 - f1: 0.7942 - val_loss: 1.1126 - val_accuracy: 0.5414 - val_f1: 0.5277\n",
      "Epoch 24/100\n",
      "35292/35292 [==============================] - 72s 2ms/step - loss: 0.4717 - accuracy: 0.8008 - f1: 0.7981 - val_loss: 1.1142 - val_accuracy: 0.5329 - val_f1: 0.5165\n",
      "Epoch 25/100\n",
      "35292/35292 [==============================] - 72s 2ms/step - loss: 0.4667 - accuracy: 0.8038 - f1: 0.8002 - val_loss: 1.1387 - val_accuracy: 0.5235 - val_f1: 0.5035\n",
      "Epoch 26/100\n",
      "35292/35292 [==============================] - 72s 2ms/step - loss: 0.4598 - accuracy: 0.8069 - f1: 0.8037 - val_loss: 1.1592 - val_accuracy: 0.5239 - val_f1: 0.5072\n",
      "Epoch 27/100\n",
      "35292/35292 [==============================] - 71s 2ms/step - loss: 0.4510 - accuracy: 0.8128 - f1: 0.8092 - val_loss: 1.1426 - val_accuracy: 0.5390 - val_f1: 0.5244\n",
      "Epoch 28/100\n",
      "35292/35292 [==============================] - 72s 2ms/step - loss: 0.4499 - accuracy: 0.8155 - f1: 0.8125 - val_loss: 1.1743 - val_accuracy: 0.5178 - val_f1: 0.4984\n",
      "Epoch 29/100\n",
      "35292/35292 [==============================] - 74s 2ms/step - loss: 0.4428 - accuracy: 0.8136 - f1: 0.8111 - val_loss: 1.1696 - val_accuracy: 0.5308 - val_f1: 0.5118\n",
      "Epoch 30/100\n",
      "35292/35292 [==============================] - 74s 2ms/step - loss: 0.4384 - accuracy: 0.8190 - f1: 0.8168 - val_loss: 1.1610 - val_accuracy: 0.5329 - val_f1: 0.5186\n",
      "Epoch 31/100\n",
      "35292/35292 [==============================] - 74s 2ms/step - loss: 0.4365 - accuracy: 0.8204 - f1: 0.8170 - val_loss: 1.1868 - val_accuracy: 0.5231 - val_f1: 0.5071\n",
      "Epoch 32/100\n",
      "35292/35292 [==============================] - 74s 2ms/step - loss: 0.4369 - accuracy: 0.8176 - f1: 0.8144 - val_loss: 1.1894 - val_accuracy: 0.5288 - val_f1: 0.5145\n",
      "Epoch 33/100\n",
      "35292/35292 [==============================] - 74s 2ms/step - loss: 0.4257 - accuracy: 0.8246 - f1: 0.8216 - val_loss: 1.1821 - val_accuracy: 0.5280 - val_f1: 0.5128\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00033: early stopping\n",
      "613/613 [==============================] - 1s 888us/step\n",
      "{'both': [1.052593126917352, 0.5432299971580505, 0.5459514856338501]}\n",
      "Training on cm\n",
      "Train on 1959 samples, validate on 490 samples\n",
      "Epoch 51/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 1.1276 - accuracy: 0.5171 - f1: 0.5010 - val_loss: 1.0023 - val_accuracy: 0.5796 - val_f1: 0.5576\n",
      "Epoch 52/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.9539 - accuracy: 0.5722 - f1: 0.5503 - val_loss: 0.9598 - val_accuracy: 0.5980 - val_f1: 0.5859\n",
      "Epoch 53/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.8599 - accuracy: 0.6105 - f1: 0.5915 - val_loss: 0.9318 - val_accuracy: 0.6000 - val_f1: 0.5917\n",
      "Epoch 54/70\n",
      "1959/1959 [==============================] - 5s 2ms/step - loss: 0.7738 - accuracy: 0.6565 - f1: 0.6315 - val_loss: 0.9225 - val_accuracy: 0.6163 - val_f1: 0.6026\n",
      "Epoch 55/70\n",
      "1959/1959 [==============================] - 5s 2ms/step - loss: 0.7291 - accuracy: 0.6738 - f1: 0.6609 - val_loss: 0.9117 - val_accuracy: 0.6204 - val_f1: 0.6072\n",
      "Epoch 56/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.6800 - accuracy: 0.7029 - f1: 0.6841 - val_loss: 0.9159 - val_accuracy: 0.6245 - val_f1: 0.6138\n",
      "Epoch 57/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.6136 - accuracy: 0.7300 - f1: 0.7222 - val_loss: 0.9139 - val_accuracy: 0.6204 - val_f1: 0.6039\n",
      "Epoch 58/70\n",
      "1959/1959 [==============================] - 5s 2ms/step - loss: 0.5728 - accuracy: 0.7606 - f1: 0.7439 - val_loss: 0.9180 - val_accuracy: 0.6143 - val_f1: 0.6000\n",
      "Epoch 59/70\n",
      "1959/1959 [==============================] - 5s 2ms/step - loss: 0.5575 - accuracy: 0.7647 - f1: 0.7498 - val_loss: 0.9310 - val_accuracy: 0.6224 - val_f1: 0.6137\n",
      "Epoch 60/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.5073 - accuracy: 0.7938 - f1: 0.7811 - val_loss: 0.9380 - val_accuracy: 0.6122 - val_f1: 0.6065\n",
      "Epoch 61/70\n",
      "1959/1959 [==============================] - 5s 2ms/step - loss: 0.4867 - accuracy: 0.8070 - f1: 0.7932 - val_loss: 0.9509 - val_accuracy: 0.6224 - val_f1: 0.6037\n",
      "Epoch 62/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.4741 - accuracy: 0.8162 - f1: 0.8051 - val_loss: 0.9606 - val_accuracy: 0.6245 - val_f1: 0.6201\n",
      "Epoch 63/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.4356 - accuracy: 0.8331 - f1: 0.8285 - val_loss: 0.9734 - val_accuracy: 0.6163 - val_f1: 0.6159\n",
      "Epoch 64/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.4017 - accuracy: 0.8489 - f1: 0.8432 - val_loss: 1.0038 - val_accuracy: 0.6163 - val_f1: 0.6163\n",
      "Epoch 65/70\n",
      "1959/1959 [==============================] - 5s 2ms/step - loss: 0.3724 - accuracy: 0.8652 - f1: 0.8555 - val_loss: 1.0114 - val_accuracy: 0.6082 - val_f1: 0.6087\n",
      "Epoch 66/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.3796 - accuracy: 0.8560 - f1: 0.8594 - val_loss: 1.0402 - val_accuracy: 0.6224 - val_f1: 0.6127\n",
      "Epoch 67/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.3474 - accuracy: 0.8703 - f1: 0.8676 - val_loss: 1.0432 - val_accuracy: 0.6224 - val_f1: 0.6158\n",
      "Epoch 68/70\n",
      "1959/1959 [==============================] - 5s 2ms/step - loss: 0.3251 - accuracy: 0.8816 - f1: 0.8776 - val_loss: 1.0764 - val_accuracy: 0.6245 - val_f1: 0.6130\n",
      "Epoch 69/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.3115 - accuracy: 0.8897 - f1: 0.8866 - val_loss: 1.0873 - val_accuracy: 0.6061 - val_f1: 0.6156\n",
      "Epoch 70/70\n",
      "1959/1959 [==============================] - 4s 2ms/step - loss: 0.2963 - accuracy: 0.8959 - f1: 0.8913 - val_loss: 1.0815 - val_accuracy: 0.6184 - val_f1: 0.6141\n",
      "613/613 [==============================] - 0s 739us/step\n",
      "{'both': [1.052593126917352, 0.5432299971580505, 0.5459514856338501], 'cm': [1.0638452632197744, 0.6231647729873657, 0.6193679571151733]}\n"
     ]
    }
   ],
   "source": [
    "model, metrics = train(model,data,\"multibpe_ct_concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'both': [1.052593126917352, 0.5432299971580505, 0.5459514856338501],\n",
       " 'cm': [1.0638452632197744, 0.6231647729873657, 0.6193679571151733]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUSE-UNSUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SentimentData.read_raw(\"../data/cm/train.txt\", \"../data/cm/test.txt\")\n",
    "data.apply_muse(\"../data/MUSE/usup/vectors-en.txt\", \"../data/MUSE/usup/vectors-es.txt\", 100000)\n",
    "data.save(\"../data/muse_usup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SentimentData.read_pickle(\"../data/muse_usup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_3 (Bidirection (None, 100)               140400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 140,703\n",
      "Trainable params: 140,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_seq_model()\n",
    "model.build(input_shape=(None,20,300))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on concat\n",
      "Train on 35292 samples, validate on 2449 samples\n",
      "Epoch 1/100\n",
      "  160/35292 [..............................] - ETA: 41:17 - loss: 1.0517 - accuracy: 0.4500 - f1: 0.0351  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (4.033836). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35292/35292 [==============================] - 60s 2ms/step - loss: 0.9158 - accuracy: 0.5529 - f1: 0.4635 - val_loss: 1.0217 - val_accuracy: 0.4741 - val_f1: 0.3446\n",
      "Epoch 2/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.8408 - accuracy: 0.6056 - f1: 0.5595 - val_loss: 0.9861 - val_accuracy: 0.5104 - val_f1: 0.3752\n",
      "Epoch 3/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.8122 - accuracy: 0.6220 - f1: 0.5830 - val_loss: 0.9722 - val_accuracy: 0.5165 - val_f1: 0.4012\n",
      "Epoch 4/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.7943 - accuracy: 0.6324 - f1: 0.5982 - val_loss: 0.9768 - val_accuracy: 0.5088 - val_f1: 0.4118\n",
      "Epoch 5/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.7783 - accuracy: 0.6435 - f1: 0.6137 - val_loss: 0.9677 - val_accuracy: 0.5194 - val_f1: 0.4247\n",
      "Epoch 6/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.7637 - accuracy: 0.6519 - f1: 0.6241 - val_loss: 0.9794 - val_accuracy: 0.5112 - val_f1: 0.4068\n",
      "Epoch 7/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.7499 - accuracy: 0.6583 - f1: 0.6313 - val_loss: 0.9613 - val_accuracy: 0.5325 - val_f1: 0.4526\n",
      "Epoch 8/100\n",
      "35292/35292 [==============================] - 48s 1ms/step - loss: 0.7364 - accuracy: 0.6681 - f1: 0.6440 - val_loss: 0.9658 - val_accuracy: 0.5284 - val_f1: 0.4520\n",
      "Epoch 9/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.7198 - accuracy: 0.6745 - f1: 0.6547 - val_loss: 0.9810 - val_accuracy: 0.5145 - val_f1: 0.4412\n",
      "Epoch 10/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.7076 - accuracy: 0.6829 - f1: 0.6623 - val_loss: 0.9742 - val_accuracy: 0.5288 - val_f1: 0.4720\n",
      "Epoch 11/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.6934 - accuracy: 0.6898 - f1: 0.6720 - val_loss: 0.9704 - val_accuracy: 0.5304 - val_f1: 0.4646\n",
      "Epoch 12/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.6806 - accuracy: 0.6980 - f1: 0.6788 - val_loss: 0.9885 - val_accuracy: 0.5076 - val_f1: 0.4388\n",
      "Epoch 13/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.6679 - accuracy: 0.7011 - f1: 0.6869 - val_loss: 1.0052 - val_accuracy: 0.5100 - val_f1: 0.4628\n",
      "Epoch 14/100\n",
      "35292/35292 [==============================] - 48s 1ms/step - loss: 0.6565 - accuracy: 0.7083 - f1: 0.6937 - val_loss: 1.0055 - val_accuracy: 0.5055 - val_f1: 0.4445\n",
      "Epoch 15/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.6440 - accuracy: 0.7177 - f1: 0.7027 - val_loss: 1.0167 - val_accuracy: 0.5043 - val_f1: 0.4367\n",
      "Epoch 16/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.6339 - accuracy: 0.7213 - f1: 0.7073 - val_loss: 1.0179 - val_accuracy: 0.5100 - val_f1: 0.4568\n",
      "Epoch 17/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.6171 - accuracy: 0.7332 - f1: 0.7200 - val_loss: 1.0189 - val_accuracy: 0.5035 - val_f1: 0.4562\n",
      "Epoch 18/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.6123 - accuracy: 0.7316 - f1: 0.7198 - val_loss: 1.0266 - val_accuracy: 0.5027 - val_f1: 0.4570\n",
      "Epoch 19/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.5987 - accuracy: 0.7406 - f1: 0.7306 - val_loss: 1.0443 - val_accuracy: 0.5002 - val_f1: 0.4496\n",
      "Epoch 20/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.5877 - accuracy: 0.7444 - f1: 0.7360 - val_loss: 1.0474 - val_accuracy: 0.4929 - val_f1: 0.4528\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00020: early stopping\n",
      "613/613 [==============================] - 0s 601us/step\n",
      "{'both': [0.9358052189354018, 0.564437210559845, 0.519957959651947]}\n",
      "Training on cm\n",
      "Train on 1959 samples, validate on 490 samples\n",
      "Epoch 51/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.9892 - accuracy: 0.5263 - f1: 0.4490 - val_loss: 0.9618 - val_accuracy: 0.5408 - val_f1: 0.4470\n",
      "Epoch 52/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.9452 - accuracy: 0.5523 - f1: 0.4611 - val_loss: 0.9533 - val_accuracy: 0.5551 - val_f1: 0.4606\n",
      "Epoch 53/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.9083 - accuracy: 0.5855 - f1: 0.5017 - val_loss: 0.9467 - val_accuracy: 0.5653 - val_f1: 0.4882\n",
      "Epoch 54/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.8851 - accuracy: 0.5860 - f1: 0.5148 - val_loss: 0.9385 - val_accuracy: 0.5633 - val_f1: 0.4890\n",
      "Epoch 55/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.8507 - accuracy: 0.6161 - f1: 0.5479 - val_loss: 0.9480 - val_accuracy: 0.5633 - val_f1: 0.5255\n",
      "Epoch 56/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.8333 - accuracy: 0.6238 - f1: 0.5529 - val_loss: 0.9402 - val_accuracy: 0.5673 - val_f1: 0.5249\n",
      "Epoch 57/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.8151 - accuracy: 0.6304 - f1: 0.6038 - val_loss: 0.9415 - val_accuracy: 0.5612 - val_f1: 0.5357\n",
      "Epoch 58/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.8144 - accuracy: 0.6376 - f1: 0.5959 - val_loss: 0.9375 - val_accuracy: 0.5776 - val_f1: 0.5373\n",
      "Epoch 59/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.7880 - accuracy: 0.6498 - f1: 0.6159 - val_loss: 0.9419 - val_accuracy: 0.5714 - val_f1: 0.5399\n",
      "Epoch 60/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.7572 - accuracy: 0.6636 - f1: 0.6294 - val_loss: 0.9443 - val_accuracy: 0.5776 - val_f1: 0.5403\n",
      "Epoch 61/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.7391 - accuracy: 0.6641 - f1: 0.6305 - val_loss: 0.9416 - val_accuracy: 0.5837 - val_f1: 0.5558\n",
      "Epoch 62/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.7237 - accuracy: 0.6866 - f1: 0.6531 - val_loss: 0.9441 - val_accuracy: 0.5796 - val_f1: 0.5521\n",
      "Epoch 63/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.7035 - accuracy: 0.6942 - f1: 0.6712 - val_loss: 0.9501 - val_accuracy: 0.5694 - val_f1: 0.5460\n",
      "Epoch 64/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.6849 - accuracy: 0.6983 - f1: 0.6755 - val_loss: 0.9518 - val_accuracy: 0.5857 - val_f1: 0.5706\n",
      "Epoch 65/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.6553 - accuracy: 0.7182 - f1: 0.7047 - val_loss: 0.9863 - val_accuracy: 0.5714 - val_f1: 0.5525\n",
      "Epoch 66/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.6468 - accuracy: 0.7208 - f1: 0.7035 - val_loss: 1.0104 - val_accuracy: 0.5694 - val_f1: 0.5408\n",
      "Epoch 67/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.6228 - accuracy: 0.7443 - f1: 0.7242 - val_loss: 0.9845 - val_accuracy: 0.5714 - val_f1: 0.5606\n",
      "Epoch 68/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.6008 - accuracy: 0.7529 - f1: 0.7262 - val_loss: 0.9894 - val_accuracy: 0.5673 - val_f1: 0.5454\n",
      "Epoch 69/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.5928 - accuracy: 0.7534 - f1: 0.7379 - val_loss: 0.9955 - val_accuracy: 0.5796 - val_f1: 0.5517\n",
      "Epoch 70/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7616 - f1: 0.7580 - val_loss: 0.9917 - val_accuracy: 0.5673 - val_f1: 0.5665\n",
      "613/613 [==============================] - 0s 576us/step\n",
      "{'both': [0.9358052189354018, 0.564437210559845, 0.519957959651947], 'cm': [0.9892003495385946, 0.5709624886512756, 0.5540029406547546]}\n"
     ]
    }
   ],
   "source": [
    "model, metrics = train(model,data,\"muse-unsup_ct_concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'both': [0.9358052189354018, 0.564437210559845, 0.519957959651947],\n",
       " 'cm': [0.9892003495385946, 0.5709624886512756, 0.5540029406547546]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUSE-SUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SentimentData.read_raw(\"../data/cm/train.txt\", \"../data/cm/test.txt\")\n",
    "data.apply_muse(\"../data/MUSE/sup/vectors-en.txt\", \"../data/MUSE/sup/vectors-es.txt\", 100000)\n",
    "data.save(\"../data/muse_sup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SentimentData.read_pickle(\"../data/muse_sup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_4 (Bidirection (None, 100)               140400    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 140,703\n",
      "Trainable params: 140,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_seq_model()\n",
    "model.build(input_shape=(None,20,300))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on concat\n",
      "Train on 35292 samples, validate on 2449 samples\n",
      "Epoch 1/100\n",
      "  160/35292 [..............................] - ETA: 28:17 - loss: 1.0485 - accuracy: 0.4250 - f1: 0.0565  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (2.651694). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35292/35292 [==============================] - 59s 2ms/step - loss: 0.9174 - accuracy: 0.5557 - f1: 0.4643 - val_loss: 1.0293 - val_accuracy: 0.4655 - val_f1: 0.3114\n",
      "Epoch 2/100\n",
      "35292/35292 [==============================] - 52s 1ms/step - loss: 0.8461 - accuracy: 0.6001 - f1: 0.5538 - val_loss: 0.9899 - val_accuracy: 0.5018 - val_f1: 0.3559\n",
      "Epoch 3/100\n",
      "35292/35292 [==============================] - 51s 1ms/step - loss: 0.8128 - accuracy: 0.6205 - f1: 0.5813 - val_loss: 0.9946 - val_accuracy: 0.5063 - val_f1: 0.3990\n",
      "Epoch 4/100\n",
      "35292/35292 [==============================] - 51s 1ms/step - loss: 0.7958 - accuracy: 0.6349 - f1: 0.5992 - val_loss: 0.9813 - val_accuracy: 0.5125 - val_f1: 0.4255\n",
      "Epoch 5/100\n",
      "35292/35292 [==============================] - 51s 1ms/step - loss: 0.7804 - accuracy: 0.6399 - f1: 0.6108 - val_loss: 0.9787 - val_accuracy: 0.5129 - val_f1: 0.4219\n",
      "Epoch 6/100\n",
      "35292/35292 [==============================] - 50s 1ms/step - loss: 0.7646 - accuracy: 0.6503 - f1: 0.6232 - val_loss: 0.9759 - val_accuracy: 0.5276 - val_f1: 0.4326\n",
      "Epoch 7/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.7526 - accuracy: 0.6571 - f1: 0.6309 - val_loss: 0.9656 - val_accuracy: 0.5378 - val_f1: 0.4417\n",
      "Epoch 8/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.7350 - accuracy: 0.6665 - f1: 0.6423 - val_loss: 0.9840 - val_accuracy: 0.5174 - val_f1: 0.4408\n",
      "Epoch 9/100\n",
      "35292/35292 [==============================] - 50s 1ms/step - loss: 0.7215 - accuracy: 0.6753 - f1: 0.6556 - val_loss: 0.9829 - val_accuracy: 0.5190 - val_f1: 0.4486\n",
      "Epoch 10/100\n",
      "35292/35292 [==============================] - 50s 1ms/step - loss: 0.7048 - accuracy: 0.6830 - f1: 0.6645 - val_loss: 0.9940 - val_accuracy: 0.5157 - val_f1: 0.4526\n",
      "Epoch 11/100\n",
      "35292/35292 [==============================] - 50s 1ms/step - loss: 0.6944 - accuracy: 0.6899 - f1: 0.6715 - val_loss: 0.9943 - val_accuracy: 0.5080 - val_f1: 0.4295\n",
      "Epoch 12/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.6776 - accuracy: 0.6988 - f1: 0.6812 - val_loss: 0.9902 - val_accuracy: 0.5284 - val_f1: 0.4670\n",
      "Epoch 13/100\n",
      "35292/35292 [==============================] - 48s 1ms/step - loss: 0.6685 - accuracy: 0.7052 - f1: 0.6896 - val_loss: 1.0014 - val_accuracy: 0.5267 - val_f1: 0.4606\n",
      "Epoch 14/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.6546 - accuracy: 0.7113 - f1: 0.6967 - val_loss: 0.9971 - val_accuracy: 0.5165 - val_f1: 0.4594\n",
      "Epoch 15/100\n",
      "35292/35292 [==============================] - 48s 1ms/step - loss: 0.6429 - accuracy: 0.7187 - f1: 0.7048 - val_loss: 1.0118 - val_accuracy: 0.5067 - val_f1: 0.4511\n",
      "Epoch 16/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.6303 - accuracy: 0.7257 - f1: 0.7138 - val_loss: 1.0217 - val_accuracy: 0.5088 - val_f1: 0.4612\n",
      "Epoch 17/100\n",
      "35292/35292 [==============================] - 50s 1ms/step - loss: 0.6131 - accuracy: 0.7316 - f1: 0.7208 - val_loss: 1.0243 - val_accuracy: 0.5280 - val_f1: 0.4833\n",
      "Epoch 18/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.6103 - accuracy: 0.7333 - f1: 0.7231 - val_loss: 1.0319 - val_accuracy: 0.5149 - val_f1: 0.4753\n",
      "Epoch 19/100\n",
      "35292/35292 [==============================] - 50s 1ms/step - loss: 0.5948 - accuracy: 0.7421 - f1: 0.7311 - val_loss: 1.0543 - val_accuracy: 0.5055 - val_f1: 0.4555\n",
      "Epoch 20/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.5831 - accuracy: 0.7483 - f1: 0.7395 - val_loss: 1.0648 - val_accuracy: 0.5145 - val_f1: 0.4723\n",
      "Epoch 21/100\n",
      "35292/35292 [==============================] - 50s 1ms/step - loss: 0.5713 - accuracy: 0.7529 - f1: 0.7450 - val_loss: 1.0655 - val_accuracy: 0.5035 - val_f1: 0.4553\n",
      "Epoch 22/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.5660 - accuracy: 0.7572 - f1: 0.7477 - val_loss: 1.0571 - val_accuracy: 0.5027 - val_f1: 0.4556\n",
      "Epoch 23/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.5585 - accuracy: 0.7630 - f1: 0.7553 - val_loss: 1.0792 - val_accuracy: 0.4965 - val_f1: 0.4668\n",
      "Epoch 24/100\n",
      "35292/35292 [==============================] - 50s 1ms/step - loss: 0.5486 - accuracy: 0.7669 - f1: 0.7586 - val_loss: 1.0778 - val_accuracy: 0.5051 - val_f1: 0.4688\n",
      "Epoch 25/100\n",
      "35292/35292 [==============================] - 50s 1ms/step - loss: 0.5379 - accuracy: 0.7708 - f1: 0.7646 - val_loss: 1.0931 - val_accuracy: 0.5153 - val_f1: 0.4782\n",
      "Epoch 26/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.5307 - accuracy: 0.7743 - f1: 0.7673 - val_loss: 1.1112 - val_accuracy: 0.4920 - val_f1: 0.4632\n",
      "Epoch 27/100\n",
      "35292/35292 [==============================] - 49s 1ms/step - loss: 0.5263 - accuracy: 0.7756 - f1: 0.7699 - val_loss: 1.1340 - val_accuracy: 0.4941 - val_f1: 0.4597\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00027: early stopping\n",
      "613/613 [==============================] - 0s 492us/step\n",
      "{'both': [0.9766581131427945, 0.5758564472198486, 0.5352863073348999]}\n",
      "Training on cm\n",
      "Train on 1959 samples, validate on 490 samples\n",
      "Epoch 51/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 1.0273 - accuracy: 0.5181 - f1: 0.4538 - val_loss: 1.0024 - val_accuracy: 0.5347 - val_f1: 0.4547\n",
      "Epoch 52/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.9587 - accuracy: 0.5319 - f1: 0.4898 - val_loss: 0.9797 - val_accuracy: 0.5571 - val_f1: 0.4674\n",
      "Epoch 53/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.9196 - accuracy: 0.5671 - f1: 0.5120 - val_loss: 0.9718 - val_accuracy: 0.5449 - val_f1: 0.4933\n",
      "Epoch 54/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.8812 - accuracy: 0.5886 - f1: 0.5384 - val_loss: 0.9737 - val_accuracy: 0.5347 - val_f1: 0.5029\n",
      "Epoch 55/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.8543 - accuracy: 0.5952 - f1: 0.5599 - val_loss: 0.9721 - val_accuracy: 0.5510 - val_f1: 0.5015\n",
      "Epoch 56/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.8264 - accuracy: 0.6182 - f1: 0.5795 - val_loss: 0.9694 - val_accuracy: 0.5347 - val_f1: 0.5018\n",
      "Epoch 57/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.8051 - accuracy: 0.6166 - f1: 0.5963 - val_loss: 0.9668 - val_accuracy: 0.5367 - val_f1: 0.4809\n",
      "Epoch 58/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.7903 - accuracy: 0.6468 - f1: 0.6092 - val_loss: 0.9765 - val_accuracy: 0.5347 - val_f1: 0.5151\n",
      "Epoch 59/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.7523 - accuracy: 0.6600 - f1: 0.6367 - val_loss: 0.9809 - val_accuracy: 0.5367 - val_f1: 0.4947\n",
      "Epoch 60/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.7342 - accuracy: 0.6784 - f1: 0.6512 - val_loss: 0.9833 - val_accuracy: 0.5408 - val_f1: 0.4869\n",
      "Epoch 61/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.7171 - accuracy: 0.6764 - f1: 0.6511 - val_loss: 0.9762 - val_accuracy: 0.5408 - val_f1: 0.5097\n",
      "Epoch 62/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.6902 - accuracy: 0.7029 - f1: 0.6842 - val_loss: 0.9792 - val_accuracy: 0.5469 - val_f1: 0.5144\n",
      "Epoch 63/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.6723 - accuracy: 0.7121 - f1: 0.6957 - val_loss: 0.9895 - val_accuracy: 0.5469 - val_f1: 0.4963\n",
      "Epoch 64/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.6419 - accuracy: 0.7254 - f1: 0.7077 - val_loss: 1.0029 - val_accuracy: 0.5429 - val_f1: 0.5030\n",
      "Epoch 65/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.6256 - accuracy: 0.7351 - f1: 0.7282 - val_loss: 1.0115 - val_accuracy: 0.5551 - val_f1: 0.5278\n",
      "Epoch 66/70\n",
      "1959/1959 [==============================] - 3s 1ms/step - loss: 0.6059 - accuracy: 0.7504 - f1: 0.7409 - val_loss: 1.0132 - val_accuracy: 0.5469 - val_f1: 0.5302\n",
      "Epoch 67/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.5834 - accuracy: 0.7545 - f1: 0.7417 - val_loss: 1.0061 - val_accuracy: 0.5510 - val_f1: 0.5287\n",
      "Epoch 68/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.5790 - accuracy: 0.7682 - f1: 0.7534 - val_loss: 1.0448 - val_accuracy: 0.5469 - val_f1: 0.5421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.5403 - accuracy: 0.7800 - f1: 0.7656 - val_loss: 1.0250 - val_accuracy: 0.5429 - val_f1: 0.5305\n",
      "Epoch 70/70\n",
      "1959/1959 [==============================] - 3s 2ms/step - loss: 0.5249 - accuracy: 0.7912 - f1: 0.7871 - val_loss: 1.0375 - val_accuracy: 0.5490 - val_f1: 0.5375\n",
      "613/613 [==============================] - 0s 559us/step\n",
      "{'both': [0.9766581131427945, 0.5758564472198486, 0.5352863073348999], 'cm': [1.0145527675723562, 0.564437210559845, 0.5661278963088989]}\n"
     ]
    }
   ],
   "source": [
    "model, metrics = train(model,data,\"muse-sup_ct_concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'both': [0.9766581131427945, 0.5758564472198486, 0.5352863073348999],\n",
       " 'cm': [1.0145527675723562, 0.564437210559845, 0.5661278963088989]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SentimentData.read_raw(\"../data/cm/train.txt\",\"../data/cm/test.txt\")\n",
    "data.apply_xlm()\n",
    "data.save(\"../data/xlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SentimentData.read_pickle(\"../data/laser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_dense_model()\n",
    "model.build(input_shape=(None,1024))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, metrics = train(model,data,\"laser_ct_concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{\n",
    "    'both': [0.7974288552561942, 0.6296900510787964, 0.6172977089881897],\n",
    "    'cm': [0.7595891077891843, 0.6639478206634521, 0.6444262266159058]\n",
    "}\n",
    "\"\"\"\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SentimentData.read_raw(\"../data/cm/train.txt\",\"../data/cm/test.txt\")\n",
    "data.apply_xlm()\n",
    "data.save(\"../data/xlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SentimentData.read_pickle(\"../data/xlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_xlm(x, pad_value, seq_len=26):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = np.array(x[i])\n",
    "        x[i] = x[i].reshape((x[i].shape[1],-1))\n",
    "        if len(x[i]) > seq_len:\n",
    "            x[i] = x[i][:seq_len]\n",
    "        else:\n",
    "            x[i] = list(x[i])\n",
    "            while len(x[i]) < seq_len:\n",
    "                x[i].append(pad_value)\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cm_x = pad_xlm(data.cm_x, [0 for _ in range(1024)], 32)\n",
    "data.en_x = pad_xlm(data.en_x, [0 for _ in range(1024)], 32)\n",
    "data.es_x = pad_xlm(data.es_x, [0 for _ in range(1024)], 32)\n",
    "data.test_x = pad_xlm(data.test_x, [0 for _ in range(1024)], 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_seq_model()\n",
    "model.build(input_shape=(None,32,1024))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, metrics = train(model,data,\"xlm_ct_concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{'both': [0.8014382719993591, 0.6231647729873657, 0.5869917869567871],\n",
    " 'cm': [0.9517435181588177, 0.650897204875946, 0.662156879901886]}\n",
    "\"\"\"\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
